const DATA = [
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Denmark",
    "Country of Researchers": "Denmark",
    "DOI": "https://doi.org/10.1002/asi.24892",
    "Title": "Screenshotting partial perspectives: The case of Danish mink in Google search results.",
    "Authors": "Renée Ridgway",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3687046",
    "Title": "Lower Quantity, Higher Quality: Auditing News Content and User Perceptions on Twitter/X Algorithmic versus Chronological Timelines.",
    "Authors": "Stephanie Wang, Shengchun Huang, Alvin Zhou, and Danaë Metaxa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Search",
    "Language": "Dutch",
    "Country Studied": "Netherlands",
    "Country of Researchers": "Netherlands, Germany",
    "DOI": "https://doi.org/10.1093/jcmc/zmae020",
    "Title": "It matters how you google it? Using agent-based testing to assess the impact of user choices in search queries and algorithmic personalization on political Google Search results.",
    "Authors": "Marieke Van Hoof, Damian Trilling, Judith Moeller, and Corine S Meppelink",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "ChatGPT, Bing, Perplexity",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search, Generative AI",
    "Language": "English",
    "Country Studied": "Canada",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1002/pra2.1021",
    "Title": "Generative AI Search Engines as Arbiters of Public Knowledge: An Audit of Bias and Authority.",
    "Authors": "Alice Li and Luanne Sinnamon",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google, Semantic Scholar",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, Germany",
    "Country of Researchers": "Germany, Switzerland, Austria",
    "DOI": "https://doi.org/10.5210/fm.v29i11.13730",
    "Title": "Examining bias perpetuation in academic search engines: An algorithm audit of Google and Semantic Scholar",
    "Authors": "Celina Kacperski, Mona Bielig, Mykola Makhortykh, Maryna Sydorova, and Roberto Ulloa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Data brokers",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization",
    "Method": "Repurposing",
    "Domain": "Ad delivery, User categorization",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Australia",
    "DOI": "https://doi.org/10.1287/mnsc.2023.4979",
    "Title": "Data Deserts and Black Boxes: The Impact of Socio-Economic Status on Consumer Profiling",
    "Authors": "Nico Neumann, Catherine E. Tucker, Levi Kaplan, Alan Mislove, and Piotr Sapiezynski",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Non-persona scrape",
    "Domain": "E-commerce",
    "Language": "Mixed",
    "Country Studied": "India, US, Germany, France",
    "Country of Researchers": "India, Germany",
    "DOI": "https://doi.org/10.1145/3686994",
    "Title": "Investigating Nudges toward Related Sellers on E-commerce Marketplaces: A Case Study on Amazon.",
    "Authors": "Abhisek Dash, Abhijnan Chakraborty, Saptarshi Ghosh, Animesh Mukherjee, and Krishna P. Gummadi",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Facebook",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3686917",
    "Title": "On the Use of Proxies in Political Ad Targeting.",
    "Authors": "Piotr Sapiezynski, Levi Kaplan, Alan Mislove, and Aleksandra Korolova",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, Harmful content, News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3648188.3675128",
    "Title": "YouTube and Conspiracy Theories: A Longitudinal Audit of Information Panels",
    "Authors": "Lillie Godinez and Eni Mustafaraj",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Filter bubble, Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/08944393231225547",
    "Title": "How Algorithms Promote Self-Radicalization: Audit of TikTok’s Algorithm Using a Reverse Engineering Method",
    "Authors": "Donghee Shin and Kulsawasd Jitkajornwanich",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Spanish",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/14604582241307836",
    "Title": "Language disparities in pandemic information: Autocomplete analysis of COVID-19 searches in New York",
    "Authors": "Vivek K Singh, Pamela Valera, Ishaan Singh, Ritesh Sawant, and Yisel Breton",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search, Recommendation",
    "Language": "English, Indonesian",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s13278-024-01343-5",
    "Title": "The bias beneath: analyzing drift in YouTube’s algorithmic recommendations",
    "Authors": "Mert Can Cakmak, Nitin Agarwal, and Remi Oni",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google, ChatGPT",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search, Generative AI",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.jse.2023.11.014",
    "Title": "Do ChatGPT and Google differ in answers to commonly asked patient questions regarding total shoulder and total elbow arthroplasty?",
    "Authors": "Shebin Tharakan, Brandon Klein, Lucas Bartlett, Aaron Atlas, Stephen A. Parada, and Randy M. Cohn",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Midjourney, DALL-E, Bing, Stable Diffusion",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Crowdsourcing",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Finland",
    "DOI": "https://doi.org/10.1145/3649217.3653596",
    "Title": "First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI",
    "Authors": "Mikko Apiola, Henriikka Vartiainen, and Matti Tedre",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Amharic",
    "Country Studied": "Ethiopia, US, UK, UAE, Saudi Arabia",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630106.3658546",
    "Title": "“I Searched for a Religious Song in Amharic and Got Sexual Content Instead’’: Investigating Online Harm in Low-Resourced Languages on YouTube",
    "Authors": "Hellina Hailu Nigatu and Inioluwa Deborah Raji",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "ChatGPT",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630106.3658932",
    "Title": "Auditing GPT’s Content Moderation Guardrails: Can ChatGPT Write Your Favorite TV Show?",
    "Authors": "Yaaseen Mahomed, Charlie M. Crawford, Sanjana Gautam, Sorelle A. Friedler, and Danaë Metaxa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3589335.3651260",
    "Title": "Comprehensively Auditing the TikTok Mobile App",
    "Authors": "Levi Kaplan and Piotr Sapiezynski",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "US, Germany, Netherlands",
    "DOI": "https://doi.org/10.1145/3589334.3645600",
    "Title": "TikTok and the Art of Personalization: Investigating Exploration and Exploitation on Social Media Feeds",
    "Authors": "Karan Vombatkere, Sepehr Mousavi, Savvas Zannettou, Franziska Roesner, and Krishna P. Gummadi",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3614419.3643996",
    "Title": "Echo Chambers in the Age of Algorithms: An Audit of Twitter’s Friend Recommender System",
    "Authors": "Kayla Duskin, Joseph S Schafer, Jevin D West, and Emma S Spiro",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630106.3658916",
    "Title": "Algorithmic Misjudgement in Google Search Results: Evidence from Auditing the US Online Electoral Information Environment",
    "Authors": "Brooke Perreault, Johanna Hoonsun Lee, Ropafadzo Shava, and Eni Mustafaraj",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google, Bing",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3589334.3645666",
    "Title": "Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results",
    "Authors": "Jeffrey Gleason, Avijit Ghosh, Ronald E. Robertson, and Christo Wilson",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Meta",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630106.3659041",
    "Title": "Auditing for Racial Discrimination in the Delivery of Education Ads",
    "Authors": "Basileal Imana, Aleksandra Korolova, and John Heidemann",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Netherlands",
    "DOI": "https://doi.org/10.1145/3614419.3644017",
    "Title": "Fact checks versus problematic content in search rankings: SEO effects and the question of Google’s content moderation",
    "Authors": "Kamila Koronska and Richard Rogers",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1001/jamanetworkopen.2024.13855",
    "Title": "Algorithmic Content Recommendations on a Video-Sharing Platform Used by Children.",
    "Authors": "Jenny Radesky, Enrica Bridgewater, Shira Black, August O’Neil, Yilin Sun, Alexandria Schaller, Heidi M. Weeks, and Scott W. Campbell",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "ChatGPT",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "UK, Cyprus",
    "DOI": "https://doi.org/10.1371/journal.pone.0300024",
    "Title": "Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity.",
    "Authors": "Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed, Martin R. Cowie, and Joel Z. Leibo",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Information quality, filter bubble",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "US, Switzerland",
    "DOI": "https://doi.org/10.1073/pnas.2313377121",
    "Title": "Causally estimating the effect of YouTube’s recommender system using counterfactual bots.",
    "Authors": "Homa Hosseinmardi, Amir Ghasemian, Miguel Rivera-Lanas, Manoel Horta Ribeiro, Robert West, and Duncan J. Watts",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, filter bubble",
    "Method": "Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s40558-023-00279-4",
    "Title": "Does algorithmic filtering lead to filter bubbles in online tourist information searches?",
    "Authors": "Yaqi Gong, Ashley Schroeder, Bing Pan, S. Shyam Sundar, and Andrew J. Mowen",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Douyin",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "Chinese",
    "Country Studied": "China",
    "Country of Researchers": "China",
    "DOI": "https://doi.org/10.1177/00936502241262056",
    "Title": "New Digital Divide Shaped by Algorithm? Evidence from Agent-Based Testing on Douyin’s Health-Related Video Recommendation",
    "Authors": "Wen Shi and Jinhui Li",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "ChatGPT",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.tele.2023.102085",
    "Title": "Exploring the limitations in how ChatGPT introduces environmental justice issues in the United States: A case study of 3,108 counties",
    "Authors": "Junghwan Kim, Jinhyung Lee, Kee Moon Jang, and Ismini Lourentzou",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Character ai",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Israel",
    "DOI": "https://doi.org/10.1177/00027642241261265",
    "Title": "Analyzing AI Bias: The Discourse of Terror and Sport Ahead of Paris 2024 Olympics",
    "Authors": "Tal Samuel-Azran, Ilan Manor, Evyatar Yitzhak, and Yair Galily",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "UK, US",
    "DOI": "https://doi.org/10.1007/s11129-024-09286-z",
    "Title": "Apparent algorithmic discrimination and real-time algorithmic learning in digital search advertising",
    "Authors": "Anja Lambrecht and Catherine Tucker",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Italian",
    "Country Studied": "US, Italy",
    "Country of Researchers": "UK, Italy",
    "DOI": "https://doi.org/10.3389/fpubh.2024.1327704",
    "Title": "Use of immunology in news and YouTube videos in the context of COVID-19: politicisation and information bubbles",
    "Authors": "Rachel Surrage George, Hannah Goodey, Maria Antonietta Russo, Rovena Tula, and Pietro Ghezzi",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Alibaba",
    "Behavior": "Exploitation",
    "Specific Behavior": "Personalization",
    "Method": "Platform-led experiment",
    "Domain": "Recommendation",
    "Language": "Chinese",
    "Country Studied": "China",
    "Country of Researchers": "US, China",
    "DOI": "https://doi.org/10.1287/mnsc.2023.4828",
    "Title": "The Value of Personal Data in Internet Commerce: A High-Stakes Field Experiment on Data Regulation Policy",
    "Authors": "Tianshu Sun, Zhe Yuan, Chunxiao Li, Kaifu Zhang, and Jun Xu",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-53503-1_11",
    "Title": "Algorithmic Amplification of Politics and Engagement Maximization on Social Media",
    "Authors": "Paul Bouchaud",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English, French, German, Italian",
    "Country Studied": "Mixed",
    "Country of Researchers": "US, Hong Kong",
    "DOI": "https://doi.org/10.1080/10584609.2024.2343769",
    "Title": "Auditing Entertainment Traps on YouTube: How Do Recommendation Algorithms Pull Users Away from News",
    "Authors": "Shengchun Huang and Tian Yang",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "Portuguese",
    "Country Studied": "Brazil",
    "Country of Researchers": "Brazil",
    "DOI": "https://doi.org/10.1002/poi3.380",
    "Title": "Recommending instead of taking down: YouTube hyperpartisan content promotion amid the Brazilian general elections",
    "Authors": "Rose Marie Santini, Débora Salles, and Bruno Mattos",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2024",
    "Organization": "DALL-E, Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI, Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/jcmc/zmad045",
    "Title": "Smiling women pitching down: auditing representational and presentational gender biases in image-generative AI.",
    "Authors": "Luhang Sun, Mian Wei, Yibing Sun, Yoo Ji Suh, Liwei Shen, and Sijia Yang",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Webcam platforms",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "Netherlands",
    "DOI": "https://doi.org/10.1177/20563051231214807",
    "Title": "Winner-Take-All? Visibility, Availability, and Heterogeneity on Webcam Sex Platforms",
    "Authors": "Emilija Jokubauskaitė, Bernhard Rieder, and Sarah Burkhardt",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "DALL-E, Starry AI",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "South Africa",
    "DOI": "https://doi.org/10.1108/DTS-01-2023-0003",
    "Title": "Epistemically violent biases in artificial intelligence design: the case of DALLE-E 2 and Starry AI",
    "Authors": "Blessing Mbalaka",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google, Bing, Baidu",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Chinese",
    "Country Studied": "Mixed",
    "Country of Researchers": "China, Canada",
    "DOI": "https://doi.org/10.1016/j.tele.2023.102068",
    "Title": "Trapped in the search box: An examination of algorithmic bias in search engine autocomplete predictions",
    "Authors": "Cong Lin, Yuxin Gao, Na Ta, Kaiyu Li, and Hongyao Fu",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Information quality, Harmful content",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "UAE",
    "DOI": "https://doi.org/10.1093/pnasnexus/pgad264",
    "Title": "YouTube’s recommendation algorithm is left-leaning in the United States",
    "Authors": "Hazem Ibrahim, Nouar AlDahoul, Sangjin Lee, Talal Rahwan, and Yasir Zaki",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Twitter",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination, User categorization",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Singapore",
    "DOI": "https://doi.org/10.1093/joc/jqac050",
    "Title": "Silenced on social media: the gatekeeping functions of shadowbans in the American Twitterverse.",
    "Authors": "Kokil Jaidka, Subhayan Mukerjee, and Yphtach Lelkes",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Italian",
    "Country Studied": "US, Italy",
    "Country of Researchers": "Netherlands",
    "DOI": "",
    "Title": "The Relationship Between Knowledge Production and Google in Framing and Reframing AI Imaginary. A Comparative Algorithmic Audit between the US and Italy",
    "Authors": "Natalia Stanusch",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, Personalization, News distribution",
    "Method": "Persona scrape",
    "Domain": "Search, Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, Switzerland",
    "DOI": "",
    "Title": "Blame It on the Algorithm? Russian Government-Sponsored Media and Algorithmic Curation of Political Information on Facebook",
    "Authors": "Elizaveta Kuznetsova and Mykola Makhortykh",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "ChatGPT",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Japan",
    "DOI": "https://doi.org/10.3389/frai.2023.1232003",
    "Title": "Revisiting the political biases of ChatGPT.",
    "Authors": "Sasuke Fujimoto and Kazuhiro Takemoto",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "DALL-E, Stable Diffusion",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "UK, Germany",
    "DOI": "https://doi.org/10.18653/v1/2023.findings-acl.502",
    "Title": "Stereotypes and Smut: The (Mis)representation of Non-cisgender Identities by Text-to-Image Models",
    "Authors": "Eddie Ungless, Bjorn Ross, and Anne Lauscher",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Bing, DuckDuckGo, Google, Yandex, Yahoo",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Russian, Chinese",
    "Country Studied": "Mixed",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1007/978-3-031-27665-1_9",
    "Title": "This Is What Pandemic Looks Like: Visual Framing of COVID-19 on Search Engines",
    "Authors": "Mykola Makhortykh, Aleksandra Urman, and Roberto Ulloa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Crowdsourcing, Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US, Spain",
    "DOI": "https://doi.org/10.2196/49061",
    "Title": "Exploring YouTube’s Recommendation System in the Context of COVID-19 Vaccines: Computational and Comparative Analysis of Video Trajectories.",
    "Authors": "Yee Man Margaret Ng, Katherine Hoffmann Pham, and Miguel Luengo-Oroz",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Russian",
    "Country Studied": "Russia, US, Germany, Ukraine, and Belarus",
    "Country of Researchers": "Germany",
    "DOI": "",
    "Title": "Googling in Russian Abroad: How Kremlin-Affiliated Websites Contribute to the Visibility of COVID-19 Conspiracy Theories in Search Results",
    "Authors": "Florian Toepfl, Anna Ryzhova, Daria Kravets, and Arista Beseler",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "French, German, Italian, English",
    "Country Studied": "France, Germany, Italy, UK",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1080/1369118X.2023.2205928",
    "Title": "‘I’m not bad, I’m just … drawn that way’: media and algorithmic systems logics in the Italian Google Images construction of (cr)immigrants’ communities",
    "Authors": "Francesca Ieracitano, Francesco Vigneri, and Francesca Comunello",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/08944393211073169",
    "Title": "Beyond Algorithmic Bias: A Socio-Computational Interrogation of the Google Search by Image Algorithm",
    "Authors": "Orestis Papakyriakopoulos and Arwa M. Mboya",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "ChatGPT, other LLM",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Generative AI",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3593013.3594078",
    "Title": "“I’m fully who I am”: Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation",
    "Authors": "Anaelia Ovalle, Palash Goyal, Jwala Dhamala, Zachary Jaggers, Kai-Wei Chang, Aram Galstyan, Richard Zemel, and Rahul Gupta",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google, Yandex",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Russian",
    "Country Studied": "Belarus",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1177/14648849231157845",
    "Title": "Different platforms, different plots? The Kremlin-controlled search engine Yandex as a resource for Russia’s informational influence in Belarus during the COVID-19 pandemic.",
    "Authors": "Daria Kravets, Anna Ryzhova, Florian Toepfl, and Arista Beseler",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "French, Spanish, Portuguese",
    "Country Studied": "France, Spain, Portugal",
    "Country of Researchers": "France, Spain, Portugal",
    "DOI": "https://doi.org/10.1002/asi.24828",
    "Title": "Shaping information and knowledge on climate change technologies: A cross‐country qualitative analysis of carbon capture and storage results on Google search.",
    "Authors": "Jussara Rowland, Sergi López‐Asensio, Ataberk Bagci, Ana Delicado, and Ana Prades",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.5117/CCR2023.1.005.ZIER",
    "Title": "Algorithmic Recommendations’ Role for the Interrelatedness of Counter-Messages and Polluted Content on YouTube – A Network Analysis",
    "Authors": "Lisa Zieringer and Diana Rieger",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google, DuckDuckGo, Yahoo",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Netherlands",
    "DOI": "https://doi.org/10.1145/3593013.3594062",
    "Title": "Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?",
    "Authors": "Alina Leidinger and Richard Rogers",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "Indonesian, English",
    "Country Studied": "Indonesia",
    "Country of Researchers": "US",
    "DOI": "",
    "Title": "Multilingual Analysis of YouTube’s Recommendation System: Examining Topic and Emotion Drift in the ‘Cheng Ho’ Narrative",
    "Authors": "",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.1007/s13278-023-01105-9",
    "Title": "Modeling rabbit-holes on YouTube",
    "Authors": "Erwan Le Merrer, Gilles Tredan, and Ali Yesilkanat",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Reddit",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s41598-023-38277-5",
    "Title": "Influencing recommendation algorithms to reduce the spread of unreliable news by encouraging humans to fact-check articles, in a field experiment",
    "Authors": "J. Nathan Matias",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Australia, Brazil",
    "DOI": "https://doi.org/10.1016/j.tele.2023.101999",
    "Title": "Bubbles bursting: Investigating and measuring the personalisation of social media searches.",
    "Authors": "Can Yang, Xinyuan Xu, Bernardo Pereira Nunes, and Sean Wolfgand Matsui Siqueira",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Online market",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Persona scrape",
    "Domain": "E-commerce",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3593013.3594038",
    "Title": "Your Browsing History May Cost You: A Framework for Discovering Differential Pricing in Non-Transparent Markets",
    "Authors": "Aditya Karan, Naina Balepur, and Hari Sundaram",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Netherlands",
    "DOI": "https://doi.org/10.1080/21670811.2023.2209153",
    "Title": "Accounting for Personalization in Personalization Algorithms: YouTube’s Treatment of Conspiracy Content",
    "Authors": "Roan Schellingerhout, Davide Beraldo, and Maarten Marx",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/20563051231196898",
    "Title": "Facebook’s News Feed Algorithm and the 2020 US Election",
    "Authors": "Jack Bandy and Nicholas Diakopoulos",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Crowdsourcing",
    "Domain": "Search, Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3544548.3580846",
    "Title": "Assessing enactment of content regulation policies: A post hoc crowd-sourced audit of election misinformation on YouTube",
    "Authors": "Prerna Juneja, Md Momen Bhuiyan, and Tanushree Mitra",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "DuckDuckGo",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/27550834231191895",
    "Title": "Assessing Trustworthiness of Internet Pharmacies with an Internet Browser Extension",
    "Authors": "Vraj Patel, Mason Lovett, Ryan Rybarczyk, and John Hertig",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/14614448231192964",
    "Title": "Algorithmic indifference: The dearth of news recommendations on TikTok",
    "Authors": "Nick Hagar and Nicholas Diakopoulos",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Online market",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Non-persona scrape",
    "Domain": "E-commerce",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3543507.3583270",
    "Title": "A Method to Assess and Explain Disparate Impact in Online Retailing",
    "Authors": "Rafael Becerril-Arreola",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google, Facebook, YouTube, Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1080/15205436.2023.2173609",
    "Title": "More of the Same? Homogenization in News Recommendations When Users Search on Google, YouTube, Facebook, and Twitter",
    "Authors": "Efrat Nechushtai, Rodrigo Zamith, and Seth C. Lewis",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Baidu, Bing, DuckDuckGo, Google, Yahoo",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, Germany",
    "Country of Researchers": "Germany, Switzerland, Finland",
    "DOI": "https://doi.org/10.1177/08944393231195471",
    "Title": "Novelty in News Search: A Longitudinal Study of the 2020 US Elections",
    "Authors": "Roberto Ulloa, Mykola Makhortykh, Aleksandra Urman, and Juhi Kulshrestha",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, German, Estonian, Belarusian, Russian, Ukrainian",
    "Country Studied": "US, Germany, Belarus, Russia, Estonia, Ukraine",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1080/1369118X.2022.2065213",
    "Title": "Who are the plotters behind the pandemic? Comparing Covid-19 conspiracy theories in Google search results across five key target countries of Russia’s foreign communication",
    "Authors": "Florian Toepfl, Daria Kravets, Anna Ryzhova, and Arista Beseler",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2023",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English, Arabic, Russian, Hebrew",
    "Country Studied": "US, UK, Nigeria, Philippines, Russia, Belarus, Kazakhstan, Egypt, Iraq, Israel",
    "Country of Researchers": "Israel, Switzerland",
    "DOI": "https://doi.org/10.1108/INTR-07-2022-0560",
    "Title": "“Is COVID-19 a hoax?”: auditing the quality of COVID-19 conspiracy-related information and misinformation in Google search results in four languages",
    "Authors": "Shakked Dabran-Zivan, Ayelet Baram-Tsabari, Roni Shapira, Miri Yitshaki, Daria Dvorzhitskaia, and Nir Grinberg",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google, Bing, Yahoo, Baidu, Yandex, DuckDuckGo",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, German",
    "Country Studied": "Germany",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1057/s41599-022-01144-1",
    "Title": "Auditing the representation of migrants in image web search results",
    "Authors": "Aleksandra Urman, Mykola Makhortykh, and Roberto Ulloa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "YouTube",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Non-persona scrape",
    "Domain": "Monetization",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US, Spain",
    "DOI": "https://doi.org/10.1145/3555209",
    "Title": "Paying Attention to the Algorithm Behind the Curtain: Bringing Transparency to YouTube’s Demonetization Algorithms.",
    "Authors": "Arun Dunna, Katherine A. Keith, Ethan Zuckerman, Narseo Vallina-Rodriguez, Brendan O’Connor, and Rishab Nithyanand",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Foundations app",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.3389/fdgth.2022.943514",
    "Title": "Foundations for fairness in digital health apps",
    "Authors": "Teodora Sandra Buda, João Guerreiro, Jesus Omana Iglesias, Carlos Castillo, Oliver Smith, and Aleksandar Matic",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "News website",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "Greek",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://doi.org/10.3390/fi14100284",
    "Title": "Modeling and Validating a News Recommender Algorithm in a Mainstream Medium-Sized News Organization: An Experimental Approach",
    "Authors": "Paschalia (Lia) Spyridou, Constantinos Djouvas, and Dimitra Milioni",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Bing, DuckDuckGo, Google, Yandex",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Russian, Ukrainian, German",
    "Country Studied": "Germany",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1177/17506980221133732",
    "Title": "Memory, counter-memory and denialism: How search engines circulate information about the Holodomor-related memory wars",
    "Authors": "Mykola Makhortykh, Aleksandra Urman, and Roberto Ulloa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google, Bing",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1145/3501247.3531567",
    "Title": "Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation",
    "Authors": "Fabian Haak and Philipp Schaer",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Germany, Brazil, US, India, Spain",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.1007/978-3-031-09316-6_5",
    "Title": "A Crowdsourcing Methodology to Measure Algorithmic Bias in Black-Box Systems: A Case Study with COVID-Related Searches",
    "Authors": "Binh Le, Damiano Spina, Falk Scholer, and Hui Chia",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Translation",
    "Language": "English, Hungarian",
    "Country Studied": "Mixed",
    "Country of Researchers": "Hungary",
    "DOI": "https://doi.org/10.1016/j.ssaho.2021.100239",
    "Title": "How to measure gender bias in machine translation: Real-world oriented machine translators, multiple reference points",
    "Authors": "Anna Farkas and Renáta Németh",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "Arabic",
    "Country Studied": "Mixed",
    "Country of Researchers": "Saudi Arabia, US",
    "DOI": "https://doi.org/10.1145/3555618",
    "Title": "Deradicalizing YouTube: Characterization, Detection, and Personalization of Religiously Intolerant Arabic Videos.",
    "Authors": "Nuha Albadi, Maram Kurdi, and Shivakant Mishra",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Gmail, Outlook, Yahoo",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Persona scrape",
    "Domain": "Spam",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3485447.3512121",
    "Title": "Left or Right: A Peek into the Political Biases in Email Spam Filtering Algorithms During US Election 2020",
    "Authors": "Hassan Iqbal, Usman Mahmood Khan, Hassan Ali Khan, and Muhammad Shahzad",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google, Yandex",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Russian",
    "Country Studied": "Mixed",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1080/1369118X.2021.1933563",
    "Title": "Gauging reference and source bias over time: how Russia’s partially state-controlled search engine Yandex mediated an anti-regime protest event",
    "Authors": "Daria Kravets and F. Toepfl",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google, Yandex",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Russian",
    "Country Studied": "Russia",
    "Country of Researchers": "Switzerland, Netherlands",
    "DOI": "https://doi.org/10.37016/mr-2020-94",
    "Title": "A story of (non)compliance, bias, and conspiracies: How Google and Yandex represented Smart Voting during the 2021 parliamentary elections in Russia",
    "Authors": "Mykola Makhortykh, Aleksandra Urman, and Mariëlle Wijermars",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1080/21670811.2022.2055596",
    "Title": "Google News and Machine Gatekeepers: Algorithmic Personalisation and News Diversity in Online News Search",
    "Authors": "Ryan Evans, Daniel Jackson, and Jaron Murphy",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google, Baidu, Bing, DuckDuckGo, Yahoo, Yandex",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1177/08944393211006863",
    "Title": "The Matter of Chance: Auditing Web Search Results Related to the 2020 U.S",
    "Authors": "Aleksandra Urman, Mykola Makhortykh, and Roberto Ulloa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Facebook, Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3512965",
    "Title": "Software-Supported Audits of Decision-Making Systems: Testing Google and Facebook’s Political Advertising Policies.",
    "Authors": "J. Nathan Matias, Austin Hounsel, and Nick Feamster",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.5210/fm.v27i12.12552",
    "Title": "Radical bubbles on YouTube? Revisiting algorithmic extremism with personalised recommendations",
    "Authors": "Mark Ledwich, Anna Zaitsev, and Anton Laukemper",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, Ireland",
    "Country of Researchers": "Switzerland",
    "DOI": "https://doi.org/10.1177/14614448221099536",
    "Title": "“Foreign beauties want to meet you”: The sexualization of women in Google’s organic and sponsored text search results",
    "Authors": "Aleksandra Urman and Mykola Makhortykh",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English, German, French",
    "Country Studied": "US, Canada, Germany",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1145/3485447.3512102",
    "Title": "An Empirical Investigation of Personalization Factors on TikTok",
    "Authors": "Maximilian Boeker and Aleksandra Urman",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Google, DuckDuckGo, Bing, Yahoo, Yandex",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, UK",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1016/j.tele.2022.101860",
    "Title": "Where the earth is flat and 9/11 is an inside job: A comparative algorithm audit of conspiratorial information in web search results",
    "Authors": "Aleksandra Urman, Mykola Makhortykh, Roberto Ulloa, and Juhi Kulshrestha",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2022",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Information quality",
    "Method": "Platform-led experiment",
    "Domain": "Recommendation",
    "Language": "English, Japanese, French, Spanish, German",
    "Country Studied": "US, UK, Japan, France, Spain, Canada, Germany",
    "Country of Researchers": "US, UK",
    "DOI": "https://doi.org/10.1073/pnas.2025334119",
    "Title": "Algorithmic amplification of politics on Twitter.",
    "Authors": "Ferenc Huszár, Sofia Ira Ktena, Conor O’Brien, Luca Belli, Andrew Schlaikjer, and Moritz Hardt",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Comparison website",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Persona scrape",
    "Domain": "E-commerce",
    "Language": "Italian",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy, US",
    "DOI": "https://doi.org/10.1145/3461702.3462569",
    "Title": "Algorithmic Audit of Italian Car Insurance: Evidence of Unfairness in Access and Pricing",
    "Authors": "Alessandro Fabris, Alan Mishler, Stefano Gottardi, Mattia Carletti, Matteo Daicampi, Gian Antonio Susto, and Gianmaria Silvello",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Persona scrape",
    "Domain": "Search",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1177/0894439319881634",
    "Title": "Googling Politics: Parties, Sources, and Issue Ownerships on Google in the 2017 German Federal Election Campaign",
    "Authors": "Julian Unkel and Mario Haim",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1145/3473856.3473864",
    "Title": "Auditing the Biases Enacted by YouTube for Political Topics in Germany",
    "Authors": "Hendrik Heuer, Hendrik Hoch, Andreas Breiter, and Yannis Theocharis",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Google, Bing, Yahoo, Yandex, DuckDuckGo",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English, Russian",
    "Country Studied": "Germany",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1145/3442442.3452306",
    "Title": "Auditing Source Diversity Bias in Video Search Results Using Virtual Agents",
    "Authors": "Aleksandra Urman, Mykola Makhortykh, and Roberto Ulloa",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US, Chile",
    "DOI": "https://doi.org/10.1145/3447535.3462491",
    "Title": "Auditing Algorithmic Bias on Twitter",
    "Authors": "Nathan Bartley, Andres Abeliuk, Emilio Ferrara, and Kristina Lerman",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Job websites",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Dutch",
    "Country Studied": "Netherlands",
    "Country of Researchers": "Netherlands",
    "DOI": "https://doi.org/10.5210/fm.v26i8.11717",
    "Title": "Gendered language and employment Web sites: How search algorithms can cause allocative harm",
    "Authors": "Karin Van Es, Daniel Everts, and Iris Muis",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Facebook, Linkedin",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3442381.3450077",
    "Title": "Auditing for Discrimination in Algorithms Delivering Job Ads",
    "Authors": "Basileal Imana, Aleksandra Korolova, and John Heidemann",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Slovakia",
    "DOI": "https://doi.org/10.1145/3460231.3474241",
    "Title": "An Audit of Misinformation Filter Bubbles on YouTube: Bubble Bursting and Recent Behavior Changes",
    "Authors": "Matus Tomlein, Branislav Pecher, Jakub Simko, Ivan Srba, Robert Moro, Elena Stefancova, Michal Kompan, Andrea Hrckova, Juraj Podrouzek, and Maria Bielikova",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/0002764221989774",
    "Title": "Evaluating Platform Accountability: Terrorist Content on YouTube",
    "Authors": "Dhiraj Murthy",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "India, Germany",
    "DOI": "https://doi.org/10.1145/3442188.3445944",
    "Title": "When the Umpire is also a Player: Bias in Private Label Product Recommendations on E-commerce Marketplaces",
    "Authors": "Abhisek Dash, Abhijnan Chakraborty, Saptarshi Ghosh, Animesh Mukherjee, and Krishna P. Gummadi",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Instagram",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Netherlands",
    "DOI": "",
    "Title": "De-coding Instagram as a Spectacle. Mediální studia 15, 02 (2021),",
    "Authors": "Lydia Kollyri",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English, Spanish, Chinese, Portuguese, Arabic",
    "Country Studied": "Mixed",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1007/978-3-030-76228-5_8",
    "Title": "YTTREX: Crowdsourced Analysis of YouTube’s Recommender System During COVID-19 Pandemic",
    "Authors": "Leonardo Sanna, Salvatore Romano, Giulia Corona, and Claudio Agosti",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3449100",
    "Title": "An Image of Society: Gender and Racial Representation and Impact in Image Search Results for Occupations.",
    "Authors": "Danaë Metaxa, Michelle A. Gan, Su Goh, Jeff Hancock, and James A. Landay",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Siri",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Sweden",
    "DOI": "https://doi.org/10.33621/jdsr.v4i1.115",
    "Title": "Exploring Siri’s Content Diversity Using a Crowdsourced Audit.",
    "Authors": "Tim Glaesener",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Persona scrape, non-persona scrape",
    "Domain": "Search, Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3411764.3445250",
    "Title": "Auditing E-Commerce Platforms for Algorithmically Curated Vaccine Misinformation",
    "Authors": "Prerna Juneja and Tanushree Mitra",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3449152",
    "Title": "More Accounts, Fewer Links: How Algorithmic Curation Impacts Media Exposure in Twitter Timelines.",
    "Authors": "Jack Bandy and Nicholas Diakopoulos",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Google, Bing",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Turkey, UK",
    "DOI": "https://doi.org/10.1007/s10791-020-09386-w",
    "Title": "Evaluation metrics for measuring bias in search engine results",
    "Authors": "Gizem Gezici, Aldo Lipani, Yucel Saygin, and Emine Yilmaz",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Alexa",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3449157",
    "Title": "Auditing the Information Quality of News-Related Queries on the Alexa Voice Assistant.",
    "Authors": "Henry Kudzanai Dambanemuya and Nicholas Diakopoulos",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search, Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/SSCI50451.2021.9660012",
    "Title": "Examining Political Bias within YouTube Search and Recommendation Algorithms",
    "Authors": "Michael Lutz, Sanjana Gadaginmath, Natraj Vairavan, and Phil Mui",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Harmful content",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/20563051211041648",
    "Title": "Curating Quality? How Twitter’s Timeline Algorithm Treats Different Types of News",
    "Authors": "Jack Bandy and Nicholas Diakopoulos",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1080/1369118X.2019.1642934",
    "Title": "Algorithmic inference, political interest, and exposure to news and politics on Facebook",
    "Authors": "Kjerstin Thorson, Kelley Cotter, Mel Medeiros, and Chankyung Pak",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3437963.3441801",
    "Title": "Ad Delivery Algorithms: The Hidden Arbiters of Political Messaging",
    "Authors": "Muhammad Ali, Piotr Sapiezynski, Aleksandra Korolova, Alan Mislove, and Aaron Rieke",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Twitter",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Crowdsourcing",
    "Domain": "User categorization",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Netherlands, Australia, Norway",
    "DOI": "https://doi.org/10.1016/j.ipm.2021.102541",
    "Title": "A little bird told me your gender: Gender inferences in social media",
    "Authors": "E. Fosch-Villaronga, A. Poulsen, R.A. Søraa, and B.H.M. Custers",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Personalization",
    "Method": "Repurposing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3449166",
    "Title": "Errors in Geotargeted Display Advertising: Good News for Local Journalism?",
    "Authors": "Jack Bandy and Brent Hecht",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "Google, Bing, DuckDuckGo",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1108/OIR-11-2018-0341",
    "Title": "An investigation of biases in web search engine query suggestions",
    "Authors": "Malte Bonart, Anastasiia Samokhina, Gernot Heisenberg, and Philipp Schaer",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Crowdsourcing",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1109/SSCI47803.2020.9308420",
    "Title": "Data Donations for Mapping Risk in Google Search of Health Queries: A case study of unproven stem cell treatments in SEM",
    "Authors": "Martin Reber, Tobias D. Krafft, Roman Krafft, Katharina A. Zweig, and Anna Couturier",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1016/j.ijmedinf.2020.104175",
    "Title": "Examining algorithmic biases in YouTube’s recommendations of vaccine videos",
    "Authors": "Deena Abul-Fottouh, Melodie Yunju Song, and Anatoliy Gruzd",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "US",
    "DOI": "",
    "Title": "A Longitudinal Analysis of YouTube’s Promotion of Conspiracy Videos",
    "Authors": "Marc Faddoul, Guillaume Chaslot, and H. Farid",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1080/10810730.2020.1776423",
    "Title": "Algorithms and Health Misinformation: A Case Study of Vaccine Books on Amazon",
    "Authors": "Jieun Shin and Thomas Valente",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Personalization",
    "Method": "Sock puppets",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3392854",
    "Title": "Measuring Misinformation in Video Search Platforms: An Audit Study on YouTube",
    "Authors": "Hussein et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Non-persona scrape, Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3351095.3372835",
    "Title": "The case for voter-centered audits of search engines during political elections",
    "Authors": "Eni Mustafaraj, Emma Lurie, and Claire Devine",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Switzerland, Brazil",
    "DOI": "https://doi.org/10.1145/3351095.3372879",
    "Title": "Auditing radicalization pathways on YouTube",
    "Authors": "Ribeiro et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Sock puppets",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/icwsm.v14i1.7276",
    "Title": "Auditing Race and Gender Discrimination in Online Housing Market",
    "Authors": "Asplund et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "Apple",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Information quality",
    "Method": "Direct scrape\nCrowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/icwsm.v14i1.7277",
    "Title": "Auditing News Curation Systems: A Case Study Examining Algorithmic and Editorial Logic in Apple News",
    "Authors": "Bandy and Diakopoulos",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Personalization, Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s41562-020-00954-0",
    "Title": "Auditing local news presence on Google News",
    "Authors": "Fischer et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "English, German",
    "Country Studied": "US, Germany",
    "Country of Researchers": "US, Germany, Taiwan",
    "DOI": "https://doi.org/10.1177/2056305120969914",
    "Title": "Birds of a Feather Get Recommended Together: Algorithmic Homophily in YouTube’s Channel Recommendations in the United States and Germany",
    "Authors": "Jonas Kaiser and Adrian Rauchfleisch",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2020",
    "Organization": "Facebook",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality",
    "Method": "Crowdsourcing",
    "Domain": "Advertising",
    "Language": "Portuguese",
    "Country Studied": "Brazil",
    "Country of Researchers": "Brazil, France",
    "DOI": "https://doi.org/10.1145/3366423.3380109",
    "Title": "Facebook Ads Monitor: An Independent Auditing System for Political Ads on Facebook",
    "Authors": "Silva et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Search",
    "Language": "Dutch, French",
    "Country Studied": "Belgium",
    "Country of Researchers": "Belgium",
    "DOI": "",
    "Title": "Does the Bubble Go Beyond?",
    "Authors": "Annelien Smets, Eladio Montero, and Pieter Ballon",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2019",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "Danish, Norwegian, Swedish",
    "Country Studied": "Denmark, Norway, Sweden",
    "Country of Researchers": "Norway",
    "DOI": "https://doi.org/10.1177/2056305118817038",
    "Title": "Comparing Platform “Ranking Cultures” Across Languages: The Case of Islam on YouTube in Scandinavia",
    "Authors": "Moe",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Personalization, Information quality",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1080/21670811.2018.1539626",
    "Title": "Beyond the bubble: Assessing the diversity of political search results",
    "Authors": "Puschmann",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "New Zealand",
    "Country of Researchers": "New Zealand",
    "DOI": "https://doi.org/10.1007/978-3-030-34971-4_17",
    "Title": "You Can’t See What You Can’t See: Experimental Evidence for How Much Relevant Information May Be Missed Due to Google’s Web Search Personalisation",
    "Authors": "Lai and Luczak-Roesch",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3308558.3313654",
    "Title": "Auditing the partisanship of Google search snippets",
    "Authors": "Hu et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://par.nsf.gov/biblio/10101277",
    "Title": "Opening Up the Black Box: Auditing Google’s Top Stories Algorithm",
    "Authors": "Lurie and Mustafaraj",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.chb.2018.07.043",
    "Title": "What kind of news gatekeepers do we want machines to be? Filter bubbles, fragmentation, and the normative dimensions of algorithmic recommendations",
    "Authors": "Efrat Nechushtai and Seth C. Lewis",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2018",
    "Organization": "Google\nTwitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Germany",
    "DOI": "https://doi.org/10.1007/s10791-018-9341-2",
    "Title": "Search bias quantification: investigating political bias in social media and web search",
    "Authors": "Kulshrestha et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3290605.3300683",
    "Title": "Search as news curator: The role of Google in shaping attention to news information",
    "Authors": "Trielli and Diakopoulos",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Facebook\nGoogle AdWords\nInstagram\nTwitter",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Carrier puppet",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "Comprehensive",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1287/mnsc.2018.3093",
    "Title": "Algorithmic bias? An empirical study of apparent gender-based discrimination in the display of stem career ads",
    "Authors": "Lambrecht and Tucker",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "LinkedIn",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3292500.3330691",
    "Title": "Fairness-aware ranking in search & recommendation systems with application to linkedin talent search",
    "Authors": "Geyik, Ambler, and Kenthapadi",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3359231",
    "Title": "Search media and elections: A longitudinal investigation of political search results in the 2018 U.S. Elections",
    "Authors": "Metaxa et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google\nBing",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3292522.3326047",
    "Title": "Auditing autocomplete: Suggestion networks and recursive algorithm interrogation",
    "Authors": "Robertson et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English, Spanish, French",
    "Country Studied": "Spain, France, Mexico, US, UK",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.3145/epi.2019.mar.13",
    "Title": "Dr. Google, what can you tell me about homeopathy? Comparative study of the top10 websites in the United States, United Kingdom, France, Mexico and Spain",
    "Authors": "Cano-Orón",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Facebook\nAcxiom\nEpsiolon\nExperian\nOracle (Datalogix)",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Crowdsourcing",
    "Domain": "Advertising",
    "Language": "Mixed",
    "Country Studied": "US, Australia, UK, Germany, France, Brazil, Japan",
    "Country of Researchers": "US, Germany",
    "DOI": "https://doi.org/10.1145/3308558.3313666",
    "Title": "Auditing Offline Data Brokers via Facebook's Advertising Platform",
    "Authors": "Venkatadri",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google\nFacebook\nOracle\nNeilsen",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Crowdsourcing",
    "Domain": "Advertising",
    "Language": "Mixed",
    "Country Studied": "US, Pakistan",
    "Country of Researchers": "US, Pakistan",
    "DOI": "https://doi.org/10.14722/ndss.2019.23392",
    "Title": "Quantity vs. Quality: Evaluating User Interest Profiles Using Ad Preference Managers",
    "Authors": "Bashir et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Exploitation",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/icwsm.v13i01.3248",
    "Title": "Measuring the Importance of User-Generated Content to Search Engines",
    "Authors": "Vincent et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Google",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Crowdsourcing",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3267323.3268962",
    "Title": "The Accuracy of the Demographic Inferences Shown on Google's Ad Settings",
    "Authors": "Tschantz et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "Dutch",
    "Country Studied": "Belgium",
    "Country of Researchers": "Belgium",
    "DOI": "https://doi.org/10.1016/j.tele.2018.07.004",
    "Title": "Challenging Google Search filter bubbles in social and political information: Disconforming evidence from a digital methods case study",
    "Authors": "Courtois, Slechten, and Coenen",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "Danish",
    "Country Studied": "Denmark",
    "Country of Researchers": "Denmark",
    "DOI": "https://doi.org/10.1080/21670811.2018.1510741",
    "Title": "Are We Exposed to the Same “News” in the News Feed?: An empirical analysis of filter bubbles as information similarity for Danish Facebook users",
    "Authors": "Bechmann and Nielbo",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Filter bubble",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "German",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1080/21670811.2017.1338145",
    "Title": "Burst of the Filter Bubble?: Effects of personalization on the diversity of Google News",
    "Authors": "Mario Haim, Andreas Graefe, and Hans-Bernd Brosius",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2018",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Mixed",
    "Country of Researchers": "Netherlands, Australia, Spain",
    "DOI": "https://doi.org/10.1177/1354856517736982",
    "Title": "From ranking algorithms to ‘ranking cultures’: Investigating the modulation of visibility in YouTube search results",
    "Authors": "Rieder, Matamoros-Fernández, and Coromina",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3274417",
    "Title": "Auditing partisan audience bias within Google search",
    "Authors": "Robertson et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Information quality",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3178876.3186143",
    "Title": "Auditing the Personalization and Composition of Politically-Related Search Engine Results Pages",
    "Authors": "Ronald E. Robertson, David Lazer, and Christo Wilson",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2018",
    "Organization": "New York Times",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, personalization",
    "Method": "Sock puppets",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "India",
    "DOI": "https://doi.org/10.1109/ASONAM.2018.8508812",
    "Title": "Analyzing the news coverage of personalized newspapers",
    "Authors": "Chakraborty and Ganguly",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Booking.com\nHotels.com\nOther websites",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Sock puppets",
    "Domain": "Pricing",
    "Language": "Mixed",
    "Country Studied": "France, Georgia, Germany, Pakistan, Russia, US",
    "Country of Researchers": "Netherlands, Germany",
    "DOI": "https://doi.org/10.1145/3176258.3176338",
    "Title": "An Empirical Study on Online Price Differentiation",
    "Authors": "Hupperich et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Indeed\nMonster\nCareerBuilder",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3173574.3174225",
    "Title": "Investigating the impact of gender on rank in resume search engines",
    "Authors": "Chen et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Facebook",
    "Behavior": "Exploitation",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Crowdsourcing",
    "Domain": "Advertising",
    "Language": "Mixed",
    "Country Studied": "EU",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.5555/3277203.3277240",
    "Title": "Unveiling and Quantifying Facebook Exploitation of Sensitive Personal Data for Advertising Purposes",
    "Authors": "Cabanas, Cuevas, and Cuevas",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "Spotify",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization",
    "Method": "Sock puppets",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "Sweden",
    "DOI": "https://doi.org/10.3384/cu.2000.1525.1792163",
    "Title": "Tracking gendered streams",
    "Authors": "Eriksson and Johansson",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "Spotify",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "Sweden",
    "DOI": "https://doi.org/10.3384/cu.2000.1525.1792184",
    "Title": "More of the Same – On Spotify Radio",
    "Authors": "Pelle Snickars",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2017",
    "Organization": "Booking.com",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/icwsm.v11i1.14898",
    "Title": "\"Be careful; Things can be worse than they appear\" - Understanding biased algorithms and users' behavior around them in rating platforms",
    "Authors": "Eslami et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "Twitter\nGoogle",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Germany",
    "DOI": "https://doi.org/10.1145/2998181.2998321",
    "Title": "Quantifying search bias: Investigating sources of bias for political searches in social media",
    "Authors": "Kulshrestha et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Not specified",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "Mixed",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1080/21670811.2017.1366865",
    "Title": "Coding the News: The role of computer code in filtering and distributing news",
    "Authors": "Weber and Kosterich",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "TaskRabbit\nFiverr",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2998181.2998327",
    "Title": "Bias in Online freelance marketplaces: Evidence from TaskRabbit and Fiverr",
    "Authors": "Hannak et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "Spotify",
    "Behavior": "Exploitation",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Direct scrape",
    "Domain": "Advertising",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "Sweden",
    "DOI": "https://doi.org/10.3384/cu.2000.1525.1792212",
    "Title": "Studying ad targeting with digital methods: The case of spotify",
    "Authors": "Mahler and Vonderau",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "Google",
    "Behavior": "Exploitation",
    "Specific Behavior": "Information quality",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/icwsm.v11i1.14883",
    "Title": "The Substantial Interdependence of Wikipedia and Google: A Case Study on the Relationship Between Peer Production Communities and Information Technologies",
    "Authors": "McMahon, Johnson, and Hecht",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2016",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Sock puppets",
    "Domain": "Mapping",
    "Language": "NA",
    "Country Studied": "Morocco, Argentina, China, India, Russia, Ukraine",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2872427.2883016",
    "Title": "MapWatch: Detecting and monitoring international border personalization on online maps",
    "Authors": "Soeller et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2016",
    "Organization": "Google, Bing",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Search",
    "Language": "Mixed",
    "Country Studied": "Diverse (shortened here for readability)",
    "Country of Researchers": "Brazil",
    "DOI": "https://doi.org/10.1007/978-3-319-47880-7_26",
    "Title": "Identifying Stereotypes in the Online Perception of Physical Attractiveness",
    "Authors": "Camila Souza Araújo, Wagner Meira, and Virgilio Almeida",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2016",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Direct scrape",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2872427.2883089",
    "Title": "An Empirical Analysis of Algorithmic Pricing on Amazon Marketplace",
    "Authors": "Chen et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2015",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Sock puppets",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2815675.2815714",
    "Title": "Location, Location, Location: The Impact of Geolocation on Web Search Personalization",
    "Authors": "Kliman-Silver et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2015",
    "Organization": "Google",
    "Behavior": "Exploitation",
    "Specific Behavior": "Personalization",
    "Method": "Persona scrape",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "",
    "Title": "Automated Experiments on Ad Privacy Settings: A Tale of Opacity, Choice, and Discrimination",
    "Authors": "Amit Datta, Michael Carl Tschantz, and Anupam Datta",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2015",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2702123.2702520",
    "Title": "Unequal Representation and Gender Stereotypes in Image Search Results for Occupations",
    "Authors": "Kay et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2014",
    "Organization": "WalMart\nExpedia\nOrbitz",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Crowdsourcing\nSock puppets",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2663716.2663744",
    "Title": "Measuring Price Discrimination and Steering on E-commerce Web Sites",
    "Authors": "Hannak et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2013",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing\nSock puppets",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2488388.2488435",
    "Title": "Measuring Personalization of Web Search",
    "Authors": "Hannak et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2013",
    "Organization": "Amazon\nHotels.com\nOther websites",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Crowdsourcing",
    "Domain": "Pricing",
    "Language": "Mixed",
    "Country Studied": "Mixed",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.1145/2535372.2535415",
    "Title": "Crowd-assisted search for price discrimination in E-commerce: First results",
    "Authors": "Mikians et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2013",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Non-persona scrape",
    "Domain": "Ad delivery",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "",
    "Title": "Discrimination in Online Ad Delivery: Google ads, black names and white names, racial discrimination, and click advertising. Queue 11, 3 (March 2013), 10–29.Crossref",
    "Authors": "Latanya Sweeney",
    "Source": "Urman et al. (2025)"
  },
  {
    "Year": "2013",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.proquest.com/docview/1771536966",
    "Title": "Google search: Hyper-visibility as a means of rendering black women and girls invisible",
    "Authors": "Noble",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2012",
    "Organization": "Google\nBing",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Sock puppets",
    "Domain": "Pricing",
    "Language": "Mixed",
    "Country Studied": "Greece, Hungary, Italy, Germany, US, Austria, UK, Poland, Spain",
    "Country of Researchers": "US, Spain",
    "DOI": "https://doi.org/10.1145/2390231.2390245",
    "Title": "Detecting price and search discrimination on the internet",
    "Authors": "Mikians et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2013",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Personalization",
    "Method": "Direct scrape",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2460276.2460278",
    "Title": "Discrimination in Online Ad Delivery",
    "Authors": "Sweeney",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Microsoft\nIBM\nFace++",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "http://proceedings.mlr.press/v81/buolamwini18a.html",
    "Title": "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification",
    "Authors": "Buolamwini and Gebru",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Amazon\nKairos",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Carrier puppet",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US, Canada",
    "Country of Researchers": "Canada, US",
    "DOI": "https://doi.org/10.1145/3306618.3314244",
    "Title": "Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial AI products",
    "Authors": "Raji and Buolamwini",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Microsoft\nClarifai\nGoogle\nAmazon\nIBM",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://arxiv.org/abs/1906.02659",
    "Title": "Does Object Recognition Work for Everyone?",
    "Authors": "DeVries et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Amazon\nGoogle\nIBM\nMicrosoft\nImagga\nClarifai",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://ojs.aaai.org/index.php/ICWSM/article/view/3232",
    "Title": "Fairness in proprietary image tagging algorithms: A cross-platform audit on people images",
    "Authors": "Kyriakou et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Amazon\nGoogle\nIBM\nMicrosoft\nClarifai",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://ojs.aaai.org/index.php/ICWSM/article/view/3255",
    "Title": "Social B(eye)as: Human and machine descriptions of people images",
    "Authors": "Barlas et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Catalonia, Spain",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "BE, ES",
    "DOI": "https://doi.org/10.1145/3322640.3326705",
    "Title": "Why machine learning may lead to unfairness: Evidence from risk assessment for juvenile justice in Catalonia",
    "Authors": "Tolan et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Sock puppets",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://ojs.aaai.org/index.php/ICWSM/article/view/7276",
    "Title": "Auditing Race and Gender Discrimination in Online Housing Market",
    "Authors": "Asplund et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2020",
    "Organization": "Jigsaw (Google)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.18653/v1/P19-1163",
    "Title": "The Risk of Racial Bias in Hate Speech Detection",
    "Authors": "Sap et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2018",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, User profiling, Filter bubble, Information quality, News distribution",
    "Method": "Crowdsourcing",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.14722/ndss.2018.23204",
    "Title": "Investigating Ad Transparency Mechanisms in Social Media: A Case Study of Facebook's Explanations",
    "Authors": "Andreou et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, News distribution, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://ojs.aaai.org/index.php/ICWSM/article/view/3229",
    "Title": "Bias misperceived: The role of partisanship and misinformation in YouTube comment moderation",
    "Authors": "Jiang, Robertson, and Wilson",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2015",
    "Organization": "Google",
    "Behavior": "Exploitation",
    "Specific Behavior": "Personalization, User profiling, Surveillance",
    "Method": "Sock puppets",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1515/popets-2015-0007",
    "Title": "Automated Experiments on Ad Privacy Settings",
    "Authors": "Datta et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Exploitation",
    "Specific Behavior": "Information quality, News distribution, Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://ojs.aaai.org/index.php/ICWSM/article/view/3248",
    "Title": "Measuring the Importance of User-Generated Content to Search Engines",
    "Authors": "Vincent et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2017",
    "Organization": "Minnesota",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/0887403415604899",
    "Title": "Out With the Old and in With the New? An Empirical Comparison of Supervised Learning Algorithms to Predict Recidivism",
    "Authors": "Duwe and Kim",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "Minnesota",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User profiling, Surveillance",
    "Method": "Direct scrape",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/0887403417718608",
    "Title": "Better Practices in the Development and Validation of Recidivism Risk Assessments: The Minnesota Sex Offender Screening Tool–4",
    "Authors": "Duwe",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2019",
    "Organization": "New York City",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, Harmful content, User profiling",
    "Method": "Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3306618.3314279",
    "Title": "The right to confront your accusers: Opening the black box of forensic DNA software",
    "Authors": "Matthews et al.",
    "Source": "2021 Review (Bandy)"
  },
  {
    "Year": "2026",
    "Organization": "Google",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Austria",
    "Country of Researchers": "India, UK",
    "DOI": "https://doi.org/10.1007/s13755-025-00412-z",
    "Title": "Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics",
    "Authors": "Bhattacharyya et al.",
    "Source": "2026 Review (Bandy)"
  },
  {
    "Year": "2026",
    "Organization": "ChatGPT-4o, Claude 4 Sonnet, Gemini 2.5 Flash, DeepSeek-V2",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Canada",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1016/j.ajoint.2026.100233",
    "Title": "Evaluation of algorithmic bias in large language models for retinal clinical recommendations",
    "Authors": "Gandhi et al.",
    "Source": "2026 Review (Bandy)"
  },
  {
    "Year": "2026",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US, Finland, SK",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1111/jedm.12420",
    "Title": "Algorithmic Bias in BERT for Response Accuracy Prediction: A Case Study for Investigating Population Validity",
    "Authors": "Gorgun and Yildirim-Erbasli",
    "Source": "2026 Review (Bandy)"
  },
  {
    "Year": "2026",
    "Organization": "N/A or not specified",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Canada",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1093/jamiaopen/ooaf171",
    "Title": "Evaluation and improvement of algorithmic fairness for COVID-19 severity classification using Explainable Artificial Intelligence-based bias mitigation",
    "Authors": "Nejadshamsi et al.",
    "Source": "2026 Review (Bandy)"
  },
  {
    "Year": "2026",
    "Organization": "OpenRent, GoodLord, Reapit",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Interview",
    "Domain": "Housing",
    "Language": "English",
    "Country Studied": "England",
    "Country of Researchers": "England",
    "DOI": "https://doi.org/10.1080/02673037.2025.2453005",
    "Title": "Algorithmic tenancies and the ordinal tenant: digital risk-profiling in England’s private rented sector",
    "Authors": "Wallace et al.",
    "Source": "2026 Review (Bandy)"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1109/TAFFC.2026.3659153",
    "Title": "A Feature-level Framework for Evaluating Demographic Biases in Facial Expression Recognition Models",
    "Authors": "Lian and Çeliktutan",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "SE, ZA",
    "Country of Researchers": "SE, UK, CH, ZA",
    "DOI": "https://doi.org/10.1016/j.ejor.2026.01.021",
    "Title": "Sensitivity-based measures of discrimination in insurance pricing",
    "Authors": "Lindholm et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "OpenAI",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1055/a-2781-9088",
    "Title": "Artificial Intelligence-Based Insurance Prior Authorization in Endoscopic Sinus and Skull Base Surgery",
    "Authors": "Halagur et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/jrsssa/qnaf003",
    "Title": "A calibrated BISG for inferring race from surname and geolocation",
    "Authors": "Greengard and Gelman",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "ChatGPT",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.14198/MEDCOM.29992",
    "Title": "Visual Communication and Content representation in AI: Algorithmic bias and data visualization in ChatGpt; Comunicación visual y representación de contenidos en la IA: sesgo algorítmico y visualización de datos en ChatGpt",
    "Authors": "González-Oñate et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "OpenAI",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-032-10721-3_41",
    "Title": "Decoding AI Narratives: Unveiling Linguistic Bias in AI Image Metadata and Its Impact",
    "Authors": "Wang and Gwebu",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Algorithmic bias, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1111/dar.70085",
    "Title": "From Clinical Trials to Real-World Impact: Introducing a Computational Framework to Detect Endpoint Bias in Opioid Use Disorder Research",
    "Authors": "Odom et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Italy, Netherlands, UK",
    "Country of Researchers": "Italy, Netherlands, UK",
    "DOI": "https://doi.org/10.1016/j.patrec.2025.11.029",
    "Title": "Assessing demographic bias in brain age prediction models using multiple deep learning paradigms",
    "Authors": "Gravina et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "AU",
    "Country of Researchers": "AU, US",
    "DOI": "https://doi.org/10.1007/978-981-95-4969-6_13",
    "Title": "Assessing Algorithmic Fairness in Socioeconomic Predictions Using Australian Census Data",
    "Authors": "Uddin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "Austrian insurance company",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Insurance",
    "Language": "English",
    "Country Studied": "AT",
    "Country of Researchers": "AT",
    "DOI": "https://doi.org/10.1007/978-3-032-11108-1_5",
    "Title": "Towards Fair AI Systems: An Insurance Case Study to Identify and Mitigate Discrimination",
    "Authors": "Resch and Hanbury",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain, Spain",
    "DOI": "https://doi.org/10.1007/978-3-032-10489-2_23",
    "Title": "A Practical Framework for Auditing Fairness in Medical AI",
    "Authors": "M Oprescu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "Adressa",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, News distribution, Personalization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "ES",
    "DOI": "https://doi.org/10.1007/978-3-032-10489-2_2",
    "Title": "A Comparative Fairness Study in News Recommendation Systems",
    "Authors": "Salcedo and Bellogín",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Algorithmic bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1007/978-3-032-08333-3_12",
    "Title": "When Bias Backfires: The Modulatory Role of Counterfactual Explanations on the Adoption of Algorithmic Bias in XAI-Supported Human Decision-Making",
    "Authors": "Kuhl and Bush",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling, Information quality",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "France, Canada, Switzerland, United States",
    "Country of Researchers": "France, Canada, France, France",
    "DOI": "https://doi.org/10.1007/978-3-032-06096-9_15",
    "Title": "P2NIA: Privacy-Preserving Non-iterative Auditing",
    "Authors": "Bourrée et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, South Korea",
    "DOI": "https://doi.org/10.1016/j.apergo.2025.104642",
    "Title": "Fairness in machine learning-based hand load estimation: A case study on load carriage tasks",
    "Authors": "Rahman et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "KR",
    "Country of Researchers": "KR",
    "DOI": "https://doi.org/10.1007/978-3-031-98284-2_7",
    "Title": "Counterfactual Fairness Evaluation of Machine Learning Models on Educational Datasets",
    "Authors": "Kim and Kim",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation, Information quality, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1007/978-3-031-93598-5_5",
    "Title": "Enhancing Structural Minority Visibility in Link Recommendations",
    "Authors": "Potka et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2026",
    "Organization": "FairNM",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "NL",
    "Country of Researchers": "NL",
    "DOI": "https://doi.org/10.1007/978-3-031-97144-0_4",
    "Title": "FairNM: Fairness in Name Matching",
    "Authors": "Liu and Frasincar",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "FAIR-Path",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US, Taiwan",
    "Country of Researchers": "US, Taiwan",
    "DOI": "https://doi.org/10.1016/j.xcrm.2025.102527",
    "Title": "Contrastive learning enhances fairness in pathology artificial intelligence systems",
    "Authors": "Lin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "IndianBailJudgments",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "IN",
    "Country of Researchers": "IN",
    "DOI": "https://doi.org/10.3233/FAIA251599",
    "Title": "From Data to Equity: Predicting and Auditing Fairness in Indian Bail Decisions",
    "Authors": "Deshmukh and Kamble",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Lithuanian peer-to-peer platform",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "LT",
    "Country of Researchers": "LT",
    "DOI": "https://doi.org/10.3390/risks13120239",
    "Title": "Gender as a Risk Factor: A Test of Gender-Neutral Pricing in Lithuania’s P2P Market",
    "Authors": "Jasas and Lastauskaite",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Bank Marketing",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3390/analytics4040026",
    "Title": "Fairness in Predictive Marketing: Auditing and Mitigating Demographic Bias in Machine Learning for Customer Targeting",
    "Authors": "Pasupuleti et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Breast Cancer Surveillance Consortium",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Canada, Netherlands, US",
    "DOI": "https://doi.org/10.1038/s41746-025-02130-y",
    "Title": "Effect of race and ethnicity on advanced breast cancer risk prediction model performance",
    "Authors": "Kerlikowske et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Cancer Genome Atlas",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, Discrimination (other), Information quality",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.1002/cpz1.70285",
    "Title": "Dataset Readiness Assessment for Training (DRAFT): A Protocol for Auditing High-Dimensional Biological Data",
    "Authors": "Guérard and Djebali",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "CHARTwatch",
    "Behavior": "Distortion",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Canada",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1093/jamiaopen/ooaf158",
    "Title": "Evaluating sociodemographic bias in a deployed machine-learned patient deterioration model",
    "Authors": "Colacci et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "YouTube, Instagram, TikTok",
    "Behavior": "Exploitation",
    "Specific Behavior": "User categorization, User profiling, Personalization, Harmful content",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.tele.2025.102341",
    "Title": "#BigTech @Minors: social media algorithms have actionable knowledge about child users and at-risk teens",
    "Authors": "Hilbert et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/jamiaopen/ooaf148",
    "Title": "Using mixture cure models to address algorithmic bias in diagnostic timing: Autism as a test case",
    "Authors": "Wu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1016/j.infsof.2025.107905",
    "Title": "Towards early detection of algorithmic bias from dataset’s bias symptoms: An empirical study",
    "Authors": "d’Aloisio et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Denmark",
    "Country of Researchers": "Denmark",
    "DOI": "https://doi.org/10.1038/s41598-025-18079-7",
    "Title": "Comparing the predictive performance of diabetes complications using administrative health data and clinical data",
    "Authors": "Aagaard et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s41746-025-01934-2",
    "Title": "Quantifying device type and handedness biases in a remote Parkinson’s disease AI-powered assessment",
    "Authors": "Tumpa et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Education",
    "Language": "German",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.1007/s40593-025-00495-5",
    "Title": "Algorithmic Fairness in Automatic Short Answer Scoring",
    "Authors": "Andersen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "TW",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s41109-025-00713-y",
    "Title": "Influence of symbolic content on recommendation bias: analyzing YouTube’s algorithm during Taiwan’s 2024 election",
    "Authors": "Cakmak and Agarwal",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "NYC Health + Hospitals",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s41746-025-01732-w",
    "Title": "Identifying and mitigating algorithmic bias in the safety net",
    "Authors": "Mackin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Poland",
    "Country of Researchers": "Poland",
    "DOI": "https://doi.org/10.1145/3746252.3761658",
    "Title": "Eliminating Bias from Presentation Attack Detection Algorithms for Face Recognition Systems",
    "Authors": "Roszczewska",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "JustEva",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Legal",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "China, US, Canada",
    "DOI": "https://doi.org/10.1145/3746252.3761491",
    "Title": "JustEva: A Toolkit to Evaluate LLM Fairness in Legal Knowledge Inference",
    "Authors": "Xue et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": " ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3757887.3763010",
    "Title": "Identity-related Speech Suppression in Generative AI Content Moderation",
    "Authors": "Proebsting et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Longitudinal Ageing Study in India (LASI)",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "India",
    "Country of Researchers": "Sweden, United States, Taiwan",
    "DOI": "https://doi.org/10.1371/journal.pdig.0000951",
    "Title": "Evaluating algorithmic fairness of machine learning models in predicting underweight, overweight, and adiposity across socioeconomic and caste groups in India: evidence from the longitudinal ageing study in India",
    "Authors": "Lee et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": " ",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Poland",
    "Country of Researchers": "Poland, US",
    "DOI": "https://doi.org/10.1007/s11192-025-05466-0",
    "Title": "Scientific software as geopolitics: evidence of national attribution bias from a large-scale replication in bibliometrics",
    "Authors": "Hensel",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "China",
    "Country of Researchers": "China",
    "DOI": "https://doi.org/10.1007/s00371-025-04160-9",
    "Title": "Towards accurate context-aware user simulation for algorithm auditing",
    "Authors": "Zhao et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "TriNetX",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1002/cpt.3758",
    "Title": "Minimizing Racial Algorithmic Bias when Predicting Electronic Health Record Data Completeness",
    "Authors": "Anand et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Palestine Technical University",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, News distribution, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Palestine",
    "Country of Researchers": "Palestine",
    "DOI": "https://doi.org/10.53671/pturj.v13i04.743",
    "Title": "Shaping Media Narratives on the Palestinian Issue: A Comparative Study of Key Generative AI Tools; ليكشتتايدرسلاةيمالعإلالوحةيضقلا:ةينيطسلفلاةساردةنراقمتاودألءاكذلايعانطصالا ةيديلوتلاةيسيئرلا",
    "Authors": "Sweileh",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Crowdsourcing, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3757620",
    "Title": "Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model",
    "Authors": "Morales-Navarro et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Crowdsourcing",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3757702",
    "Title": "WeAudit: Scaffolding User Auditors and AI Practitioners in Auditing Generative AI",
    "Authors": "Deng et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "CN",
    "Country of Researchers": "CN",
    "DOI": "https://doi.org/10.1145/3757414",
    "Title": "'I Know You Are Discriminatory!': Automated Substantiating for Individual Fairness Auditing of AI Systems",
    "Authors": "Liu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "fintech platforms",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Algeria",
    "DOI": "https://doi.org/10.1556/032.2025.00134",
    "Title": "Algorithmic credit allocation and the rise of financial inequality: Evidence from U.S. fintech platforms",
    "Authors": "Touitou",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Ipsos",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1001/jamanetworkopen.2025.36870",
    "Title": "Adolescents’ Daily Race-Related Online Experiences and Mental Health Outcomes",
    "Authors": "Tynes et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Veterans Health Administration",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/jamiaopen/ooaf115",
    "Title": "Evaluating the impact of data biases on algorithmic fairness and clinical utility of machine learning models for prolonged opioid use prediction",
    "Authors": "Naderalvojoud et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3746059.3747798",
    "Title": "Why am i seeing this: Democratizing End User Auditing for Online Content Recommendations",
    "Authors": "Chen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "ChatGPT, Microsoft Copilot",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Greece",
    "Country of Researchers": "Greece",
    "DOI": "https://doi.org/10.1007/s44230-025-00109-2",
    "Title": "Algorithmic Governance: Gender Bias in AI-Generated Policymaking?",
    "Authors": "Voutyrakou and Skordoulis",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Four pan-European insurers",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "EU",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3390/risks13090160",
    "Title": "Algorithmic Bias Under the EU AI Act: Compliance Risk, Capital Strain, and Pricing Distortions in Life and Health Insurance Underwriting",
    "Authors": "Mahajan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "DALL-E, Flux 1",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.3390/journalmedia6030110",
    "Title": "Visual Representations in AI: A Study on the Most Discriminatory Algorithmic Biases in Image Generation",
    "Authors": "Vargas-Veleda et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.jbef.2025.101081",
    "Title": "Are credit scores gender-neutral? Evidence of mis-calibration from alternative and traditional borrowing data",
    "Authors": "Liu and Liang",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Open University",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.18608/jla.2025.8543",
    "Title": "Unveiling Accuracy-Fairness Trade-Offs: Investigating Machine Learning Models in Student Performance Prediction",
    "Authors": "Opoku et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "DiffRec",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "France, Italy, Belgium",
    "Country of Researchers": "France, Italy, Belgium",
    "DOI": "https://doi.org/10.1145/3705328.3759318",
    "Title": "How Fair is Your Diffusion Recommender Model?",
    "Authors": "Malitesta et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Yelp",
    "Behavior": "Distortion",
    "Specific Behavior": "Popularity Bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Austria",
    "DOI": "https://doi.org/10.1145/3705328.3748017",
    "Title": "Exploring the Effect of Context-Awareness and Popularity Calibration on Popularity Bias in POI Recommendations",
    "Authors": "Forster et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3233/SHTI251025",
    "Title": "Algorithmic Fairness in Machine Learning Prediction of Autism Using Electronic Health Records",
    "Authors": "Angell et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "FairFML",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Singapore",
    "Country of Researchers": "Singapore, US",
    "DOI": "https://doi.org/10.3233/SHTI251245",
    "Title": "FairFML: A Unified Approach to Algorithmic Fair Federated Learning with Applications to Reducing Gender Disparities in Cardiac Arrest Outcomes",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Hate speech, Harmful content, Information quality",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Search",
    "Language": "German",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.1177/14614448241244735",
    "Title": "Influence of hate speech about refugees in search algorithms on political attitudes: An online experiment",
    "Authors": "Pradel",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Turkish AI Surveillance Systems",
    "Behavior": "Discrimination",
    "Specific Behavior": "Surveillance, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Surveillance",
    "Language": "Turkish",
    "Country Studied": "TR",
    "Country of Researchers": "BG, TR",
    "DOI": "https://doi.org/10.3390/app15169038",
    "Title": "SCRAM: A Scenario-Based Framework for Evaluating Regulatory and Fairness Risks in AI Surveillance Systems",
    "Authors": "Kesgin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Organization: ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US, UK",
    "Country of Researchers": "Hungary",
    "DOI": "https://doi.org/10.1007/s42979-025-04222-8",
    "Title": "Lending by Algorithm: Fair or Flawed? An Information-Theoretic View of Credit Decision Pipelines",
    "Authors": "Abbas",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "NSQIP",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s00464-025-11927-7",
    "Title": "Fairness of machine learning readmission predictions following open ventral hernia repair",
    "Authors": "Zander et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, UK, GB",
    "DOI": "https://doi.org/10.1007/s42001-025-00382-y",
    "Title": "‘Slightly disappointing’ vs. ‘worst sh** ever’: tackling cultural differences in negative sentiment expressions in AI-based sentiment analysis",
    "Authors": "Hafner et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Organization not specified in abstract",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, US",
    "DOI": "https://doi.org/10.1145/3733155.3737371",
    "Title": "Informing Human Decision-Making in Public Administration through NLP Algorithm Audits",
    "Authors": "Fonner and Coyle",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Denmark, US",
    "DOI": "https://doi.org/10.1145/3698205.3733933",
    "Title": "Fairness Over Time: A Nationwide Study of Evolving Bias in Dropout Prediction",
    "Authors": "Blažková et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content, Personalization, User profiling",
    "Method": "Sock puppets",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "SK",
    "Country of Researchers": "Slovakia",
    "DOI": "https://doi.org/10.1145/3726302.3730293",
    "Title": "Revisiting Algorithmic Audits of TikTok: Poor Reproducibility and Short-term Validity of Findings",
    "Authors": "Mosnar et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "MT, RS",
    "Country of Researchers": "MT, RS",
    "DOI": "https://doi.org/10.3390/math13132183",
    "Title": "Mitigating Algorithmic Bias Through Probability Calibration: A Case Study on Lead Generation Data",
    "Authors": "Nikolic et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Epic",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/jamia/ocaf062",
    "Title": "External validation of a proprietary risk model for 1-year mortality in community-dwelling adults aged 65 years or older",
    "Authors": "Frechman et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Facebook",
    "Behavior": "Discrimination",
    "Specific Behavior": "Filter bubble, User categorization, Personalization, News distribution",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s41558-025-02326-w",
    "Title": "Facebook algorithm’s active role in climate advertisement delivery",
    "Authors": "Sankaranarayanan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "IN",
    "Country of Researchers": "IN",
    "DOI": "https://doi.org/10.1108/DPRG-05-2024-0090",
    "Title": "Algorithmic solutions, subjectivity and decision errors: a study of AI accountability",
    "Authors": "Biju and Gayathri",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "Dutch",
    "Country Studied": "NL",
    "Country of Researchers": "NL",
    "DOI": "https://doi.org/10.1145/3715275.3732065",
    "Title": "Dangerous Criminals and Beautiful Prostitutes? Investigating Harmful Representations in Dutch Language Models",
    "Authors": "Lin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "GeoMatch, Annie™ Moore, Match'In, Re:Match",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.1145/3715275.3732149",
    "Title": "Location matching on shaky grounds: Re-evaluating algorithms for refugee allocation",
    "Authors": "Strasser Ceballos and Kern",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google, OpenAI, Anthropic, Meta, Cohere, AI21 Labs",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Germany, UK",
    "Country of Researchers": "Germany, UK, US",
    "DOI": "https://doi.org/10.1145/3715275.3732038",
    "Title": "Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)",
    "Authors": "Neumann et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality, News distribution, Personalization",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732190",
    "Title": "When Collaborative Filtering is not Collaborative: Unfairness of PCA for Recommendations",
    "Authors": "Liu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732137",
    "Title": "A Framework for Auditing Chatbots for Dialect-Based Quality-of-Service Harms",
    "Authors": "Harvey et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Meta",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732170",
    "Title": "External Evaluation of Discrimination Mitigation Efforts in Meta's Ad Delivery",
    "Authors": "Imana et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Twitter/X",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Filter bubble, Information quality, News distribution, User profiling",
    "Method": "Sock puppets",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732159",
    "Title": "Auditing Political Exposure Bias: Algorithmic Amplification on Twitter/X during the 2024 U.S. Presidential Election",
    "Authors": "Ye et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "New York City",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732004",
    "Title": "Auditing the Audits: Lessons for Algorithmic Accountability from Local Law 144's Bias Audits",
    "Authors": "Gerchick et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "GPT-3.5, e-commerce-specific LLM",
    "Behavior": "Distortion, Misjudgement",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, US",
    "DOI": "https://doi.org/10.1145/3715275.3732169",
    "Title": "Understanding Gender Bias in AI-Generated Product Descriptions",
    "Authors": "Kelly et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732156",
    "Title": "AI constructs gendered struggle narratives: Implications for self-concept and systems design.",
    "Authors": "Fitzsimons et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Crowdsourcing",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732167",
    "Title": "Discrimination Exposed? on the Reliability of Explanations for Discrimination Detection",
    "Authors": "Skirzynski et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Meta",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1145/3715275.3732196",
    "Title": "The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models",
    "Authors": "Ovalle et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732123",
    "Title": "Bias Delayed is Bias Denied? Assessing the Effect of Reporting Delays on Disparity Assessments",
    "Authors": "Gosciak et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "None",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization",
    "Method": "Direct scrape",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "SE",
    "Country of Researchers": "UK, SE",
    "DOI": "https://doi.org/10.1145/3715275.3732016",
    "Title": "Classifying Hate: Legal and Ethical Evaluations of ML-Assisted Hate Crime Classification and Estimation in Sweden",
    "Authors": "Sargeant et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "11 leading commercial LLM services and open-sourced models",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "Simplified Chinese, Traditional Chinese, English",
    "Country Studied": "China, Taiwan, US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732182",
    "Title": "Characterizing Bias: Benchmarking Large Language Models in Simplified versus Traditional Chinese",
    "Authors": "Lyu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Crowdsourcing",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3715275.3732142",
    "Title": "Investigating Youth AI Auditing",
    "Authors": "Solyst et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender Stereotypes, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "UK, Italy",
    "DOI": "https://doi.org/10.1145/3713043.3731495",
    "Title": "Experts Unite, Kids Delight: Co-Designing an Inclusive AI Literacy Educational Tool for Children",
    "Authors": "Collyer-Hoar et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content, Information quality, News distribution, Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3699682.3728350",
    "Title": "Circumventing Misinformation Controls: Assessing the Robustness of Intervention Strategies in Recommender Systems",
    "Authors": "Pathak and Spezzano",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Filter bubble, Information quality",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Spain, Chile",
    "Country of Researchers": "Spain, Chile, Italy",
    "DOI": "https://doi.org/10.1016/j.jjimei.2024.100311",
    "Title": "Enhancing recommender systems with provider fairness through preference distribution-awareness",
    "Authors": "Gómez et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "India, UK",
    "Country of Researchers": "India, UK",
    "DOI": "https://doi.org/10.1109/TCSS.2024.3509340",
    "Title": "Toward Exploring Fairness in Visual Transformer Based Natural and GAN Image Detection Systems",
    "Authors": "P. Gangan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "JAEB Center for Health Research",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Denmark, Netherlands, France, Luxembourg, Germany, Netherlands, Netherlands",
    "DOI": "https://doi.org/10.1371/journal.pdig.0000918",
    "Title": "Racial disparities in continuous glucose monitoring-based 60-min glucose predictions among people with type 1 diabetes",
    "Authors": "Thomsen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US, Louisiana, New Jersey, New Mexico, Utah",
    "Country of Researchers": "US, Germany",
    "DOI": "https://doi.org/10.1093/jamiaopen/ooaf033",
    "Title": "Evaluating algorithmic bias on biomarker classification of breast cancer pathology reports",
    "Authors": "Miller et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.artmed.2025.103130",
    "Title": "Exploring trade-offs in equitable stroke risk prediction with parity-constrained and race-free models",
    "Authors": "Engelhard et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Arkansas All-Payer Claims Database",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.37765/ajmc.2025.89737",
    "Title": "Predictive Models for Low Birth Weight: A Comparative Analysis of Algorithmic Fairness–Improving Approaches",
    "Authors": "Brown et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "NRG Oncology",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US, Canada",
    "Country of Researchers": "US, Canada",
    "DOI": "https://doi.org/10.1200/CCI-24-00284",
    "Title": "Assessing Algorithmic Fairness With a Multimodal Artificial Intelligence Model in Men of African and Non-African Origin on NRG Oncology Prostate Cancer Phase III Trials",
    "Authors": "Roach et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "ChatGPT, DeepSeek, LLaMA 3.3, Claude 3.7",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, News distribution, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "NL, CA, UK",
    "Country of Researchers": "NL, CA, UK",
    "DOI": "https://doi.org/10.1098/rsos.241776",
    "Title": "Generalization bias in large language model summarization of scientific research",
    "Authors": "Peters and Chin-Yee",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "University",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Sock puppets, Crowdsourcing",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1145/3706598.3713714",
    "Title": "\"Here the GPT made a choice, and every choice can be biased\": How Students Critically Engage with LLMs through End-User Auditing Activity",
    "Authors": "Prabhudesai et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Vipera",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3706599.3719757",
    "Title": "Vipera: Towards systematic auditing of generative text-to-image models at scale",
    "Authors": "Huang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "DALLE, Midjourney, Stable Diffusion",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "CN, US",
    "Country of Researchers": "CN, US",
    "DOI": "https://doi.org/10.1145/3706599.3719678",
    "Title": "Imagining the Far East: Exploring Perceived Biases in AI-Generated Images of East Asian Women",
    "Authors": "Lan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": " ",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1145/3706598.3713963",
    "Title": "Access Denied: Meaningful Data Access for Quantitative Algorithm Audits",
    "Authors": "Zaccour et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI, Amazon",
    "Behavior": "Discrimination, Distortion, Exploitation",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Content Moderation, Social Media",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1145/3706598.3713998",
    "Title": "Lost in Moderation: How Commercial Content Moderation APIs Over- and Under-Moderate Group-Targeted Hate Speech and Linguistic Variations",
    "Authors": "Hartmann et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "J.P. Morgan AI Research",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/aaai.v39i16.33847",
    "Title": "Auditing and Enforcing Conditional Fairness via Optimal Transport",
    "Authors": "Ghassemi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "US, UK",
    "DOI": "https://doi.org/10.1192/bjo.2025.32",
    "Title": "Machine learning for prediction of childhood mental health problems in social care",
    "Authors": "Crowley et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Upwork",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, France",
    "DOI": "https://doi.org/10.1016/j.jbusres.2025.115298",
    "Title": "Opening the ‘black box’ of HRM algorithmic biases – How hiring practices induce discrimination on freelancing platforms",
    "Authors": "Trautwein et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Clinical available artificial intelligence model",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "China",
    "Country of Researchers": "China",
    "DOI": "https://doi.org/10.1007/s00234-024-03536-3",
    "Title": "Evaluating a clinically available artificial intelligence model for intracranial aneurysm detection: a multi-reader study and algorithmic audit",
    "Authors": "Hu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Basque Country",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "UK, ES",
    "DOI": "https://doi.org/10.1007/s00146-024-02016-9",
    "Title": "Judging the algorithm: Algorithmic accountability on the risk assessment tool for intimate partner violence in the Basque Country",
    "Authors": "Valdivia et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "Sweden",
    "DOI": "https://doi.org/10.1371/journal.pone.0318338",
    "Title": "Visual digital intermediaries and global climate communication: Is climate change still a distant problem on YouTube?",
    "Authors": "Segerberg and Magnani",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google, Meta, Amazon",
    "Behavior": "Exploitation",
    "Specific Behavior": "Surveillance, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1177/14614448251314401",
    "Title": "Tracking menopause: An SDK Data Audit for intimate infrastructures of datafication with ChatGPT4o",
    "Authors": "Pybus and Mir",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "SpartaScience™",
    "Behavior": "Distortion",
    "Specific Behavior": "User profiling, Harmful content, Information quality",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1249/MSS.0000000000003610",
    "Title": "Algorithmic Audits in Sports Medicine: An Examination of the SpartaScience™ Force Plate System",
    "Authors": "Butler et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1126/sciadv.adq0305",
    "Title": "Demographic bias of expert-level vision-language foundation models in medical imaging",
    "Authors": "Yang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3706468.3706521",
    "Title": "XAI Reveals the Causes of Attention Deficit Hyperactivity Disorder (ADHD) Bias in Student Performance Prediction",
    "Authors": "Lee et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Affectnet",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "ES",
    "DOI": "https://doi.org/10.1007/s13748-024-00345-w",
    "Title": "Less can be more: representational vs. stereotypical gender bias in facial expression recognition",
    "Authors": "Dominguez-Catena et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1002/pam.22569",
    "Title": "Are algorithms biased in education? Exploring racial bias in predicting community college student success",
    "Authors": "Bird et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "ChatGPT-4",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "Spanish",
    "Country Studied": "ES",
    "Country of Researchers": "ES",
    "DOI": "https://doi.org/10.3390/socsci14030170",
    "Title": "Social Biases in AI-Generated Creative Texts: A Mixed-Methods Approach in the Spanish Context",
    "Authors": "Gabino-Campos et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, News distribution, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/pnasnexus/pgaf062",
    "Title": "Engagement, user satisfaction, and the amplification of divisive content on social media",
    "Authors": "Milli et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "ChatGPT, Microsoft Copilot",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, Misinformation",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English, Russian, Ukrainian",
    "Country Studied": "Switzerland, Germany, Ukraine",
    "Country of Researchers": "Germany, Switzerland, Switzerland",
    "DOI": "https://doi.org/10.1007/s42001-024-00338-8",
    "Title": "In generative AI we trust: can chatbots effectively verify political information?",
    "Authors": "Kuznetsova et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1371/journal.pone.0314470",
    "Title": "Gender and racial bias issues in a commercial “tone of voice” analysis system",
    "Authors": "Holliday and Reed",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Quantum AI for Dark Web Narcotics Detection: A Hybrid Cybersecurity Framework",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Surveillance, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "International",
    "Country of Researchers": "Costa Rica",
    "DOI": "https://doi.org/10.4108/airo.10248",
    "Title": "Quantum AI for Dark Web Narcotics Detection: A Hybrid Cybersecurity Framework",
    "Authors": "Silva-Atencio",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Microsoft Copilot",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "TW",
    "Country of Researchers": "SE, ES",
    "DOI": "https://doi.org/10.1177/14614448251321162",
    "Title": "AI chatbot accountability in the age of algorithmic gatekeeping: Comparing generative search engine political information retrieval across five languages",
    "Authors": "Kuai et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "assalaabnk",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-79103-1_13",
    "Title": "Impact of Skin Tone Diversity on Out-of-Distribution Detection Methods in Dermatology",
    "Authors": "Benmalek et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Organization: ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.imu.2025.101627",
    "Title": "Learning unbiased risk prediction based algorithms in healthcare: A case study with primary care patients",
    "Authors": "Gupta et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "X (formerly Twitter)",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-78538-2_3",
    "Title": "Impacts of Personalization on Social Network Exposure",
    "Authors": "Bartley et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, Personalization",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "France",
    "Country of Researchers": "France, Switzerland",
    "DOI": "https://doi.org/10.1007/978-3-031-78538-2_8",
    "Title": "Browsing Amazon’s Book Bubbles",
    "Authors": "Bouchaud",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.1007/s10994-024-06721-w",
    "Title": "Fair prediction sets through multi-objective hyperparameter optimization",
    "Authors": "García-Galindo et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Arkansas All Payers Claims Database",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s40615-025-02296-x",
    "Title": "Fairness in Low Birthweight Predictive Models: Implications of Excluding Race/Ethnicity",
    "Authors": "Brown et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, News distribution, Filter bubble, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "Chinese",
    "Country Studied": "CN",
    "Country of Researchers": "CN",
    "DOI": "https://doi.org/10.1080/21670811.2025.2450312",
    "Title": "News Diversity Under Algorithms: The Effects of Pre-Selected and Self-Selected Personalization on Chinese TikTok (Douyin)",
    "Authors": "Shi and Li",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Meta",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, User categorization, User profiling, Price discrimination",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Social Media, Political Campaigns",
    "Language": "English",
    "Country Studied": "Netherlands",
    "Country of Researchers": "Netherlands, US",
    "DOI": "https://doi.org/10.1080/10584609.2024.2439317",
    "Title": "The Cost of Reach: Testing the Role of Ad Delivery Algorithms in Online Political Campaigns",
    "Authors": "Votta et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Filter bubble, Personalization, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Search, Recommendation",
    "Language": "English",
    "Country Studied": "",
    "Country of Researchers": "",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208636462&partnerID=40&md5=0db0ffd14592958b1f2f769f9dcfd8d6",
    "Title": "5th International Workshop on Algorithmic Bias in Search and Recommendation, BIAS 2024",
    "Authors": "",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon",
    "Behavior": "Exploitation",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1007/978-3-031-71975-2_1",
    "Title": "An Offer You Cannot Refuse? Trends in the Coercive Impact of Amazon Book Recommendations",
    "Authors": "Rystrøm",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "TikTok",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "Chinese",
    "Country Studied": "CN",
    "Country of Researchers": "CN",
    "DOI": "https://doi.org/10.1080/10410236.2024.2414882",
    "Title": "Accessing the Impact of TikTok’s Algorithm on Regional Inequality in Health Information",
    "Authors": "Li and Shi",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code, Crowdsourcing",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1080/0960085X.2024.2395531",
    "Title": "Reducing the incidence of biased algorithmic decisions through feature importance transparency: an empirical study",
    "Authors": "Ebrahimi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Cambridge Analytica",
    "Behavior": "Exploitation",
    "Specific Behavior": "Manipulation, User profiling, User categorization, Harmful content",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "India",
    "DOI": "https://doi.org/10.1002/9781394386574.ch11",
    "Title": "Algorithmic Bias and Psychographic Profiling for Manipulation",
    "Authors": "Rawat and Rajavat",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "FairHealthGrid",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias Mitigation, Information quality, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105025435667&partnerID=40&md5=54d9eb7e1ce4e754bd89f365fd56b379",
    "Title": "FairHealthGrid: A Systematic Framework for Evaluating Bias Mitigation Strategies in Healthcare Machine Learning",
    "Authors": "de Paiva et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "India",
    "Country of Researchers": "India",
    "DOI": "https://doi.org/10.1109/ICoEIT63558.2025.11211699",
    "Title": "Exploring the Impact of Algorithmic Bias on Information Access and User Behavior in Web Search",
    "Authors": "Salman et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Facebook, New York University, University of Mississippi",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, UK, Netherlands, Germany, China",
    "DOI": "https://doi.org/10.1080/13645579.2025.2598616",
    "Title": "Reaching across the political aisle: overcoming challenges in using social media for recruiting politically diverse respondents",
    "Authors": "Macdonald et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.1007/s10639-025-13857-2",
    "Title": "Explainable pedagogical alignment: auditing LLMs with learning theories",
    "Authors": "Figaredo et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Exploitation",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "France, Switzerland",
    "Country of Researchers": "France, Switzerland, Netherlands, US, Germany",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023641872&partnerID=40&md5=b7977e86a79781c3fd3ae5d461622f88",
    "Title": "Robust ML Auditing using Prior Knowledge",
    "Authors": "Bourrée et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Austria, Spain",
    "Country of Researchers": "Austria, Spain",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105023637200&partnerID=40&md5=c18b3789807a1117ff5a99e4ad85c147",
    "Title": "The Disparate Benefits of Deep Ensembles",
    "Authors": "Schweighofer et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Carnegie Learning, Inc.",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.5281/zenodo.15870165",
    "Title": "Fairness of Bayesian Knowledge Tracing for Math Learners of Different Reading Ability",
    "Authors": "Stinar et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google, DuckDuckGo",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Personalization, Information quality",
    "Method": "Direct scrape, Sock puppets, Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "Portugal",
    "DOI": "https://doi.org/10.1109/ACCESS.2025.3635871",
    "Title": "Unequal Content: search engine personalization influences exposure to information regarding the Israel-Palestine conflict",
    "Authors": "Damião et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Gender misrepresentation, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.5220/0013835600004000",
    "Title": "Are all Genders Equal in the Eyes of Algorithms? Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness",
    "Authors": "Urchs et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI, Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Romania, UK",
    "Country of Researchers": "Romania, UK",
    "DOI": "https://doi.org/10.1109/RoEduNet68395.2025.11208334",
    "Title": "Bias Detection in AI Recruitment. Transparency, Accountability and Empirical Assessment Using Synthetic CVs and Rapid Testing",
    "Authors": "State and Olar",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, Personalization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Spain, France",
    "Country of Researchers": "France, Spain",
    "DOI": "https://doi.org/10.1080/07421222.2025.2561382",
    "Title": "Social Identity Theory and Algorithmic Bias: Ingroup and Outgroup Acrophily in Recommender Systems",
    "Authors": "Carrasco-Farré et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Beijing Huilongguan Hospital",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "Mandarin",
    "Country Studied": "CN",
    "Country of Researchers": "CN, FR",
    "DOI": "https://doi.org/10.1109/AIoTC66747.2025.11198722",
    "Title": "Bias Identification in Deep Learning-Based Psychological Hotline Models∗",
    "Authors": "Zhang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Organization: ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Financial services",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s10506-025-09485-3",
    "Title": "Causal-GNN for ethical AI in financial services: ensuring fairness, compliance, and transparency in automated decision-making",
    "Authors": "Vallarino",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Twitch",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "India, US",
    "DOI": "https://doi.org/10.18653/v1/2025.acl-long.1110",
    "Title": "Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch",
    "Authors": "Shukla et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.21437/Interspeech.2025-2700",
    "Title": "J-j-j-just Stutter: Benchmarking Whisper's Performance Disparities on Different Stuttering Patterns",
    "Authors": "Sridhar and Wu",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3389/feduc.2025.1592037",
    "Title": "Audit-style framework for evaluating bias in large language models",
    "Authors": "Baldwin",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Bangladesh",
    "Country of Researchers": "Bangladesh",
    "DOI": "https://doi.org/10.1109/QPAIN66474.2025.11171992",
    "Title": "Unmasking AI Bias in Traditional Prognosis Models",
    "Authors": "Hasan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ACDSA65407.2025.11166624",
    "Title": "Keeping track of the kids: A deep dive into object detector fairness for pedestrians of different ages",
    "Authors": "Friant et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "PROGRxN-BCa",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Canada, US, Europe",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1016/j.eururo.2025.09.4145",
    "Title": "Development and International Evaluation of an Artificial Intelligence–based Model (PROGRxN-BCa) Using the World Health Organization 2004/2022 Grading System to Predict Progression Risk and Improve Substratification for Non–muscle-invasive Bladder Cancer",
    "Authors": "Kwong et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Cityscapes",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Europe",
    "Country of Researchers": "US, Canada",
    "DOI": "https://doi.org/10.1109/CVPRW67362.2025.00068",
    "Title": "Classification Drives Geographic Bias in Street Scene Segmentation",
    "Authors": "Nair et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "FairDITA",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "KR, DE",
    "Country of Researchers": "KR, DE",
    "DOI": "https://doi.org/10.1007/s10278-025-01693-2",
    "Title": "FairDITA: Disentangled Image-Text Alignment for Fair Skin Cancer Diagnosis",
    "Authors": "Park et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, South Korea",
    "DOI": "https://doi.org/10.1080/15213269.2025.2558036",
    "Title": "Racial Bias in AI Training Data: Do Laypersons Notice?",
    "Authors": "Chen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Instagram, TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Personalization",
    "Method": "Sock puppets",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Switzerland, Germany",
    "Country of Researchers": "Switzerland, Germany",
    "DOI": "https://doi.org/10.1109/MIPRO65660.2025.11131921",
    "Title": "Visualizing Children's Filter Bubbles: A Digital Window for Bridging Social Media Experiences",
    "Authors": "Bekavac et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "ChatGPT3.5, ChatGPT4, Gemini, Bing Chat",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Singapore, China",
    "Country of Researchers": "Singapore, China",
    "DOI": "https://doi.org/10.1108/INTR-10-2024-1536",
    "Title": "Digital prejudices: an analysis of gender, racial and religious biases in generative AI chatbots",
    "Authors": "Chua et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ETHICS65148.2025.11098270",
    "Title": "How Do Human and AI Gender Bias Interact in Hiring Decisions?",
    "Authors": "Getahun et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Fraunhofer",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, Algorithmic Fairness",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Austria",
    "Country of Researchers": "Austria, Germany",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014400477&partnerID=40&md5=01dd475ad12364fb66441b704acbc670",
    "Title": "AI Certification and Assessment Catalogues:Practical Use and Challenges in the Context of the European AI Act",
    "Authors": "Autischer et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Law School, Bank Marketing, COMPAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Surveillance, User profiling, User categorization, Group misrepresentation, Harmful content, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Netherlands",
    "Country of Researchers": "Netherlands",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014374385&partnerID=40&md5=310a12087d8b3af932d1da2f85412bb7",
    "Title": "Exposing Hidden Vulnerabilities: A Privacy Audit of Algorithmic Fairness",
    "Authors": "Purkait et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/14614448251346503",
    "Title": "Examining racial stereotypes in YouTube autocomplete suggestions",
    "Authors": "Ha et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Carnegie Learning",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1007/978-3-031-98465-5_43",
    "Title": "Evaluating an AI Tutor for Bias Across Different Foundation Models",
    "Authors": "Vinodh et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "MA",
    "Country of Researchers": "MO",
    "DOI": "https://doi.org/10.1007/978-3-031-98462-4_46",
    "Title": "On the Fairness of Ensemble Learning Methods in Student Dropout Prediction",
    "Authors": "Aboukacem et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-98420-4_14",
    "Title": "Investigating Racial and Skin Tone Biases in Automated Classification of Teachers’ Activities in Classroom Videos",
    "Authors": "Drimalla et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "COMPAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "UK, Canada",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011199235&partnerID=40&md5=4b6abfc7846c470d3d3b0f63077aa0e0",
    "Title": "The Overstated Cost of AI Fairness in Criminal Justice",
    "Authors": "Cofone and Khern-Am-Nuai",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "MagicSchool AI",
    "Behavior": "Distortion, Exploitation",
    "Specific Behavior": "Harmful content, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1080/17439884.2025.2527920",
    "Title": "‘I hope this email finds you well’: how synthetic affect circulates through MagicSchool AI",
    "Authors": "Robinson and Leander",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "FairSense",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICSE55347.2025.00159",
    "Title": "FairSense: Long-Term Fairness Analysis of ML-Enabled Systems",
    "Authors": "She et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICSE55347.2025.00070",
    "Title": "Fairness Testing Through Extreme Value Theory",
    "Authors": "Monjezi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "OpenAI",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code, Crowdsourcing",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010265810&partnerID=40&md5=56c895939326a80eb732959a9e243b79",
    "Title": "FIRST-PERSON FAIRNESS IN CHATBOTS",
    "Authors": "Eloundou et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Ocular Disease Recognition (ODIR)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Italy, UK",
    "Country of Researchers": "Italy, UK",
    "DOI": "https://doi.org/10.1007/978-3-031-95841-0_59",
    "Title": "Domain-Adversarial Neural Networks to Explore Biases in the Diagnosis of Multiple Eye Conditions from Fundus Image Data",
    "Authors": "Pullega et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Large Language Modelsbased recruitment tool",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other), Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/SIEDS65500.2025.11021210",
    "Title": "Beyond Traditional Biases in AI Hiring: Exposing the Hidden Systemic Challenges in Resume Screening",
    "Authors": "Bhatnagar et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Greek prison system",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "GR",
    "Country of Researchers": "GR",
    "DOI": "https://doi.org/10.1109/IRASET64571.2025.11008007",
    "Title": "Towards Fair Recidivism Prediction: Addressing Bias in Machine Learning for the Greek Prison System",
    "Authors": "Oikonomou et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, Personalization",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, US",
    "DOI": "https://doi.org/10.24251/hicss.2025.304",
    "Title": "Unpacking Algorithmic Bias in YouTube Shorts by Analyzing Thumbnails",
    "Authors": "Cakmak and Agarwal",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Pennsylvania",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1090/psapm/080/00729",
    "Title": "Uncertainty in criminal justice algorithms: Simulation studies of the Pennsylvania Additive Classification Tool",
    "Authors": "Dhar et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Amazon Rekognition, Deep Face, Fair Face, BadgerCake",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/CITREx64975.2025.10974934",
    "Title": "Algorithmic Bias Detection: A Focus on Skin Tone and Gender Fairness in AI Models",
    "Authors": "Iguare and Taiwo",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "COMPAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1007/978-3-031-90643-5_4",
    "Title": "Stream-Based Monitoring of Algorithmic Fairness",
    "Authors": "Baumeister et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "TikTok",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, User profiling, Filter bubble, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "NL, US",
    "Country of Researchers": "NL",
    "DOI": "https://doi.org/10.1080/17512786.2025.2479499",
    "Title": "Fighting Fire with Fire: Journalistic Investigations of Artificial Intelligence Using Artificial Intelligence Techniques",
    "Authors": "Veerbeek",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Cardiac Atlas Project",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "China, UK, Algeria, South Korea",
    "Country of Researchers": "China, UK, Algeria, South Korea",
    "DOI": "https://doi.org/10.3390/diagnostics14232675",
    "Title": "Mitigating Algorithmic Bias in AI-Driven Cardiovascular Imaging for Fairer Diagnostics",
    "Authors": "Sufian et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.1016/j.caeai.2024.100303",
    "Title": "AI-based prediction of academic success: Support for many, disadvantage for some?",
    "Authors": "Herrmann and Weigert",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, User categorization, User profiling",
    "Method": "Sock puppets",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "France",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.1007/s41109-024-00668-6",
    "Title": "Auditing the audits: evaluating methodologies for social media recommender system audits",
    "Authors": "Bouchaud and Ramaciotti",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "China, US",
    "DOI": "https://doi.org/10.1016/j.chb.2024.108408",
    "Title": "Biased search engine autosuggestions against females and immigrants can lead to hiring discrimination: An experimental investigation",
    "Authors": "Lin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Open University",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1016/j.caeai.2024.100267",
    "Title": "Investigating algorithmic bias in student progress monitoring",
    "Authors": "Idowu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Facebook",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "Spain",
    "DOI": "https://doi.org/10.1140/epjds/s13688-024-00473-2",
    "Title": "Online advertisement in a pink-colored market",
    "Authors": "Mehrjoo et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s44184-024-00057-y",
    "Title": "Measuring algorithmic bias to analyze the reliability of AI tools that predict depression risk using smartphone sensed-behavioral data",
    "Authors": "Adler et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Featurespace Limited",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK, US",
    "DOI": "https://doi.org/10.1145/3677052.3698666",
    "Title": "Evaluating Fairness in Transaction Fraud Models: Fairness Metrics, Bias Audits, and Challenges",
    "Authors": "Kamalaruban et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "GPT-4",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3689904.3694709",
    "Title": "Racial Steering by Large Language Models: A Prospective Audit of GPT-4 on Housing Recommendations",
    "Authors": "Liu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "OpenAI",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3689904.3694699",
    "Title": "The Silicon Ceiling: Auditing GPT's Race and Gender Biases in Hiring",
    "Authors": "Armstrong et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3679318.3685411",
    "Title": "Reflective Design for Informal Participatory Algorithm Auditing: A Case Study with Emotion AI",
    "Authors": "Howell et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "global music streaming service",
    "Behavior": "Distortion",
    "Specific Behavior": "Algorithmic Bias, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "France, US",
    "DOI": "https://doi.org/10.1145/3640457.3688065",
    "Title": "Do Recommender Systems Promote Local Music? A Reproducibility Study Using Music Streaming Data",
    "Authors": "Matrosova et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": " ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Carrier puppet, Crowdsourcing, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1007/s00146-023-01726-w",
    "Title": "More or less discrimination? Practical feasibility of fairness auditing of technologies for personnel selection",
    "Authors": "Mihaljevic et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/23794607251320229",
    "Title": "Auditing large language models for race & gender disparities: Implications for artificial intelligence-based hiring",
    "Authors": "Gaebler et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "United States CW agency",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Canada, US",
    "DOI": "https://doi.org/10.1145/3670947.3670976",
    "Title": "Beyond Predictive Algorithms in Child Welfare",
    "Authors": "Moon et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google, Facebook, Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Algorithmic bias, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1287/isre.2019.0493",
    "Title": "The Anchoring Effect, Algorithmic Fairness, and the Limits of Information Transparency for Emotion Artificial Intelligence",
    "Authors": "Rhue",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Crystal Island",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s40593-023-00379-6",
    "Title": "Detecting and Mitigating Encoded Bias in Deep Learning-Based Stealth Assessment Models for Reflection-Enriched Game-Based Learning Environments",
    "Authors": "Gupta et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content, Information quality, News distribution, Personalization, User profiling",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3664190.3672520",
    "Title": "Cognitively Biased Users Interacting with Algorithmically Biased Results in Whole-Session Search on Debated Topics",
    "Authors": "Wang and Liu",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "GPT-4",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code, Crowdsourcing",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands, US",
    "DOI": "https://doi.org/10.1371/journal.pclm.0000429",
    "Title": "Can large language models estimate public opinion about global warming? An empirical assessment of algorithmic fidelity and bias",
    "Authors": "Lee et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Johns Hopkins Bloomberg School of Public Health",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.jbi.2024.104683",
    "Title": "Assessing racial bias in healthcare predictive models: Practical lessons from an empirical evaluation of 30-day hospital readmission models",
    "Authors": "Wang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Veterans Health Administration",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.jbi.2024.104664",
    "Title": "Evaluating accuracy and fairness of clinical decision support algorithms when health care resources are limited",
    "Authors": "Meerwijk et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "EthnicityEstimator, NamePrism, Ethnicolr",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "Germany, United Kingdom",
    "DOI": "https://doi.org/10.1007/s00146-022-01619-4",
    "Title": "Equal accuracy for Andrew and Abubakar—detecting and mitigating bias in name-ethnicity classification algorithms",
    "Authors": "Hafner et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "FinRegistry",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "FI",
    "Country of Researchers": "FI, US, SE, GB",
    "DOI": "https://doi.org/10.1038/s43587-024-00657-5",
    "Title": "Deep learning-based prediction of one-year mortality in Finland is an accurate but unfair aging marker",
    "Authors": "Vabalas et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Misinformation, Filter bubble, Echo Chambers, Information quality, News distribution, Personalization, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630744.3658615",
    "Title": "Stemming the Tide of Problematic Information in Online Environments: Assessing Interventions and Identifying Opportunities for Interruption",
    "Authors": "Duskin",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Organization not explicitly mentioned in the provided text.",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, US",
    "DOI": "https://doi.org/10.1145/3630106.3658974",
    "Title": "One Model Many Scores: Using Multiverse Analysis to Prevent Fairness Hacking and Evaluate the Influence of Model Design Decisions",
    "Authors": "Simson et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Open AI",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630106.3658996",
    "Title": "Careless Whisper: Speech-to-Text Hallucination Harms",
    "Authors": "Koenecke et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Decision Support",
    "Behavior": "Discrimination, Misjudgement",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "DK",
    "Country of Researchers": "DK, IT, US",
    "DOI": "https://doi.org/10.1145/3630106.3658906",
    "Title": "Failing Our Youngest: On the Biases, Pitfalls, and Risks in a Decision Support Algorithm Used for Child Protection",
    "Authors": "Moreau et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "DE, US",
    "Country of Researchers": "DE, US, GB",
    "DOI": "https://doi.org/10.1145/3630106.3658902",
    "Title": "Ethnic Classifications in Algorithmic Fairness: Concepts, Measures and Implications in Practice",
    "Authors": "Jaime and Kern",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Null Compliance",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Crowdsourcing, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3630106.3658998",
    "Title": "Null Compliance: NYC Local Law 144 and the challenges of algorithm accountability",
    "Authors": "Wright et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1007/s11023-024-09663-3",
    "Title": "Towards Transnational Fairness in Machine Learning: A Case Study in Disaster Response Systems",
    "Authors": "Kozcuer et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "United States National Outbreak Reporting System (NORS)",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1057/s41271-024-00477-2",
    "Title": "Missingness and algorithmic bias: an example from the United States National Outbreak Reporting System, 2009–2019",
    "Authors": "Diemer and Naumova",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google, Bing, Baidu, Yandex",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "DE, US",
    "Country of Researchers": "DE, CH, AT, US",
    "DOI": "https://doi.org/10.1177/14614448221100699",
    "Title": "Representativeness and face-ism: Gender bias in image search",
    "Authors": "Ulloa et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Behavioral-Informatics-Lab",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3614419.3644028",
    "Title": "Accuracy and Fairness for Web-Based Content Analysis under Temporal Shifts and Delayed Labeling",
    "Authors": "Almuzaini et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "Bengali",
    "Country Studied": "US, Canada",
    "Country of Researchers": "US, Canada",
    "DOI": "https://doi.org/10.1145/3613904.3642669",
    "Title": "The “Colonial Impulse” of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases",
    "Authors": "Das et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "JupyterLab",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, US",
    "DOI": "https://doi.org/10.1145/3613904.3642755",
    "Title": "JupyterLab in Retrograde: Contextual Notifications That Highlight Fairness and Bias Issues for Data Scientists",
    "Authors": "Harrison et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Algorithmic bias",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Netherlands, US",
    "Country of Researchers": "Netherlands, US",
    "DOI": "https://doi.org/10.1016/j.chb.2023.108128",
    "Title": "Beyond traditional interviews: Psychometric analysis of asynchronous video interviews for personality and interview performance evaluation using machine learning",
    "Authors": "Koutsoumpis et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Aiberry",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Singapore, UK, Netherlands, China, Germany, Arizona",
    "DOI": "https://doi.org/10.1016/j.jad.2024.01.212",
    "Title": "Conversational assessment using artificial intelligence is as clinically useful as depression scales and preferred by users",
    "Authors": "Weisenburger et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Danish Named Entity Recognition tools",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "DK",
    "Country of Researchers": "DK",
    "DOI": "https://doi.org/10.1093/llc/fqad091",
    "Title": "Epistemic consequences of unfair tools",
    "Authors": "Lassen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Social Media Platform",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, Personalization",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "France",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.1007/s42001-024-00255-w",
    "Title": "Skewed perspectives: examining the influence of engagement maximization on content diversity in social media feeds",
    "Authors": "Bouchaud",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "MIMIC-CXR, ADNI",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Taiwan, US, Netherlands, Germany",
    "DOI": "https://doi.org/10.1016/j.ebiom.2024.105047",
    "Title": "Drop the shortcuts: image augmentation improves fairness and decreases AI detection of race and other demographics from medical images",
    "Authors": "Wang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Mapping",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.apgeog.2024.103244",
    "Title": "You are where you live? Evaluating the racial and ethnic (mis)representation in geodemographic classification",
    "Authors": "Lin",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Social Network",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "France",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.1016/j.techfore.2023.123204",
    "Title": "Artificial intelligence and algorithmic bias? Field tests on social network with teens",
    "Authors": "Cecere et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "YouTube, Google Search, Twitter, Facebook, TikTok, Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), Harmful content, Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Canada",
    "DOI": "https://doi.org/10.1016/j.ijinfomgt.2023.102743",
    "Title": "8–10% of algorithmic recommendations are ‘bad’, but… an exploratory risk-utility meta-analysis and its regulatory implications",
    "Authors": "Hilbert et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1007/s10207-023-00774-z",
    "Title": "Fairness as a Service (FaaS): verifiable and privacy-preserving fairness auditing of machine learning systems",
    "Authors": "Toreini et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Germany, Switzerland",
    "Country of Researchers": "Germany, Switzerland",
    "DOI": "https://doi.org/10.1177/01655515221093029",
    "Title": "Scaling up search engine audits: Practical insights for algorithm auditing",
    "Authors": "Ulloa et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": " ",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3636555.3636890",
    "Title": "Investigating Algorithmic Bias on Bayesian Knowledge Tracing and Carelessness Detectors",
    "Authors": "Zambrano et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Carnegie Learning, Inc.",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3636555.3636869",
    "Title": "Hierarchical Dependencies in Classroom Settings Influence Algorithmic Bias Metrics",
    "Authors": "Belitz et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "DE, US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3614407.3643698",
    "Title": "Orthogonalizing Inputs",
    "Authors": "Gillis",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "User categorization, User profiling, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1287/msom.2022.0132",
    "Title": "Popularity Bias in Online Dating Platforms: Theory and Empirical Evidence",
    "Authors": "Celdir et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Klinikum Rechts der Isar, Munich, Bayern, Germany",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://doi.org/10.1016/j.ebiom.2024.105002",
    "Title": "(Predictable) performance bias in unsupervised anomaly detection",
    "Authors": "Meissen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Japan",
    "Country of Researchers": "Japan",
    "DOI": "https://doi.org/10.1016/j.infsof.2023.107390",
    "Title": "Diversity-aware fairness testing of machine learning classifiers through hashing-based sampling",
    "Authors": "Zhao et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Uber, Hestia. ai",
    "Behavior": "Exploitation",
    "Specific Behavior": "User profiling, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "CH",
    "Country of Researchers": "FR",
    "DOI": "https://doi.org/10.5210/fm.v29i2.13576",
    "Title": "Governing work through personal data: The case of Uber drivers in Geneva",
    "Authors": "Pidoux et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Germany, Australia, UK",
    "Country of Researchers": "Germany, Australia, UK, US",
    "DOI": "https://doi.org/10.1192/bjp.2023.141",
    "Title": "Algorithmic fairness in precision psychiatry: analysis of prediction models in individuals at clinical high risk for psychosis",
    "Authors": "Şahin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "CalEnviroScreen",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Mapping",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands, China, USA",
    "DOI": "https://doi.org/10.1038/s42256-024-00793-y",
    "Title": "Mitigating allocative tradeoffs and harms in an environmental justice data tool",
    "Authors": "Huynh et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "HLAEquity",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Information quality, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.isci.2023.108613",
    "Title": "HLAEquity: Examining biases in pan-allele peptide-HLA binding predictors",
    "Authors": "Conev et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/WACV57701.2024.00464",
    "Title": "Linking convolutional kernel size to generalization bias in face analysis CNNs",
    "Authors": "Liang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Hewlett Packard Enterprise",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/WACV57701.2024.00436",
    "Title": "Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness",
    "Authors": "Sarkar et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias Detection, Group misrepresentation, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Sweden, Greece",
    "Country of Researchers": "Sweden, Greece",
    "DOI": "https://doi.org/10.1109/ICDM59182.2024.00025",
    "Title": "CounterFair: Group Counterfactuals for Bias Detection, Mitigation and Subgroup Identification",
    "Authors": "Kuratomi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/FMLDS63805.2024.00063",
    "Title": "Promoting Equity: Assessing Algorithmic Fairness in Machine Learning Approaches for Predicting Alzheimer's Disease",
    "Authors": "Zhang",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "FairCVdb",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219579084&partnerID=40&md5=c1b29e4d0e29fc23797dc57aab62ecc9",
    "Title": "Exploring Fusion Techniques in Multimodal AI-Based Recruitment: Insights from FairCVdb",
    "Authors": "Swati et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "PH",
    "Country of Researchers": "NL, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219543947&partnerID=40&md5=9e71fbc6d471f42ad9abd14b0ed975d3",
    "Title": "Algorithmic Fairness in Geo-intelligence Workflows through Causality",
    "Authors": "Masinde et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Job Market Finland (JMF)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, Personalization",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "FI",
    "Country of Researchers": "PT",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219517761&partnerID=40&md5=a87b3ad7c6ead452b1fa51d7ce1ad6df",
    "Title": "Building Job Seekers’ Profiles: Can LLMs Level the Playing Field?",
    "Authors": "Lavado and Zejnilović",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/BigData62323.2024.10825978",
    "Title": "Algorithmic Lending Bias: Evaluating the Fairness of Historical Redlining in Loan Approvals",
    "Authors": "Sarwal and Islam",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Organization: The name(s) of the company/platform/system being audited (e.g., Google, Facebook, Amazon). Use newline to separate multiple. If unclear, leave blank.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.2196/63289",
    "Title": "Survival After Radical Cystectomy for Bladder Cancer: Development of a Fair Machine Learning Model",
    "Authors": "Carbunaru et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content, Personalization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/VDS63897.2024.00009",
    "Title": "Interactive Counterfactual Exploration of Algorithmic Harms in Recommender Systems",
    "Authors": "Ahn et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Denmark",
    "Country of Researchers": "Denmark",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210828063&partnerID=40&md5=e55a576fabea554222847a102ec9f7db",
    "Title": "Literary Canonicity and Algorithmic Fairness: The Effect of Author Gender on Classification Models",
    "Authors": "Lassen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/hcomp.v12i1.31602",
    "Title": "Investigating What Factors Influence Users’ Rating of Harmful Algorithmic Bias and Discrimination",
    "Authors": "Kingsley et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Self-preferencing",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, India, Switzerland, US",
    "DOI": "https://doi.org/10.1628/jite-2024-0014",
    "Title": "Antitrust, Amazon, and Algorithmic Auditing",
    "Authors": "Dash et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "IBM, Microsoft",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Algeria, US, Kenya",
    "Country of Researchers": "Algeria, US, Kenya",
    "DOI": "https://doi.org/10.1109/ISBI56570.2024.10635847",
    "Title": "Evaluating the Impact of Skin Tone Representation on Out-of-Distribution Detection Performance in Dermatology",
    "Authors": "Benmalek et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Filter bubble, Harmful content, Information quality",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-72241-7_20",
    "Title": "Unveiling Bias in YouTube Shorts: Analyzing Thumbnail Recommendations and Topic Dynamics",
    "Authors": "Cakmak et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Filter bubble, Group misrepresentation",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "BY",
    "Country of Researchers": "Germany",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200345017&partnerID=40&md5=2a3e8ee3733d07b9018bb24a433c9c13",
    "Title": "Search Engines as “Globalizing Machines”: International News Flow Through Google During the 2020 Belarusian Presidential Election",
    "Authors": "Kravets",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "iMotions",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-64299-9_7",
    "Title": "Identifying and Mitigating Algorithmic Bias in Student Emotional Analysis",
    "Authors": "Ashwin and Biswas",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/23328584241258741",
    "Title": "Inside the Black Box: Detecting and Mitigating Algorithmic Bias Across Racialized Groups in College Student-Success Prediction",
    "Authors": "Gándara et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Economic Research Institute, Far Eastern Branch, Russian Academy of Sciences",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "Russian",
    "Country Studied": "RU",
    "Country of Researchers": "RU",
    "DOI": "https://doi.org/10.14530/se.2024.2.071-092",
    "Title": "Spatial Algorithmic Bias in Socio-Economic Clustering of Russian Regions; Пространственная алгоритмическая предвзятость в социально-экономической кластеризации российских регионов",
    "Authors": "Blanutsa",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google, Facebook, Amazon",
    "Behavior": "Exploitation",
    "Specific Behavior": "Misinformation monetization, Harmful content, News distribution",
    "Method": "Direct scrape, Code",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1109/SP54263.2024.00003",
    "Title": "The Inventory is Dark and Full of Misinformation: Understanding Ad Inventory Pooling in the Ad-Tech Supply Chain",
    "Authors": "Vekaria et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195191082&partnerID=40&md5=f70bb6cae4a05e2a7c689df570628463",
    "Title": "UNPROCESSING SEVEN YEARS OF ALGORITHMIC FAIRNESS",
    "Authors": "Cruz and Hardt",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Organization: ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/AIMHC59811.2024.00051",
    "Title": "Evaluating and Improvi g the Performance and Racial Fairness of Algori ims for GFR Estimation",
    "Authors": "Zhang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Organization: ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "India",
    "Country of Researchers": "India",
    "DOI": "https://doi.org/10.1109/WACVW60836.2024.00067",
    "Title": "Does the Fairness of Your Pre-Training Hold Up? Examining the Influence of Pre-Training Techniques on Skin Tone Bias in Skin Lesion Classification",
    "Authors": "Seth and Pai",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Algorithmic biases, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "India",
    "Country of Researchers": "India",
    "DOI": "https://doi.org/10.1109/IC2PCT60090.2024.10486757",
    "Title": "Ethical Considerations in the Use of Deep Learning for HR Decision-Making",
    "Authors": "Singh et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "None",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US, MD, FL",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.2196/47125",
    "Title": "Evaluating Algorithmic Bias in 30-Day Hospital Readmission Models: Retrospective Analysis",
    "Authors": "Wang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany, Netherlands",
    "DOI": "https://doi.org/10.1007/978-3-031-47715-7_18",
    "Title": "Algorithmic Fairness in Healthcare Data with Weighted Loss and Adversarial Learning",
    "Authors": "Das et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Australia",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.1109/TLT.2024.3351352",
    "Title": "When the Past != The Future: Assessing the Impact of Dataset Drift on the Fairness of Learning Analytics Models",
    "Authors": "Deho et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.5281/zenodo.12729810",
    "Title": "Examining the Algorithmic Fairness in Predicting High School Dropouts",
    "Authors": "Pan and Zhang",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "EPFL",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "Switzerland",
    "Country of Researchers": "Switzerland",
    "DOI": "https://doi.org/10.5281/zenodo.12729856",
    "Title": "Investigation of behavioral Differences: Uncovering Behavioral Sources of Demographic Bias in Educational Algorithms",
    "Authors": "Cock et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "University in the Philippines",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "PH",
    "Country of Researchers": "US, JP, FR",
    "DOI": "https://doi.org/10.5281/zenodo.12729936",
    "Title": "Evaluating Algorithmic Bias in Models for Predicting Academic Performance of Filipino Students",
    "Authors": "Švábenský et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105018582187&partnerID=40&md5=5db9707a4a73185bf6a089e431d5bf1c",
    "Title": "Statistical Inference for Fairness Auditing",
    "Authors": "Cherian and Candés",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution, Personalization",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, Germany, Italy",
    "Country of Researchers": "Germany, Italy, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000545069&partnerID=40&md5=5397555ba9bc24dc8011bfbadebd2e63",
    "Title": "An engine not a camera: Measuring performative power of online search",
    "Authors": "Mendler-Dünner et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000492460&partnerID=40&md5=25be82919527b0c7ddcd45de759ded09",
    "Title": "Conformal Classification with Equalized Coverage for Adaptively Selected Groups",
    "Authors": "Zhou and Sesia",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "ADNI",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, Netherlands, US",
    "DOI": "https://doi.org/10.1186/s13195-023-01225-6",
    "Title": "Higher performance for women than men in MRI-based Alzheimer’s disease detection",
    "Authors": "Klingenberg et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "SAIS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US, Germany",
    "Country of Researchers": "US, Germany",
    "DOI": "https://doi.org/10.1038/s41746-023-00766-2",
    "Title": "Human visual explanations mitigate bias in AI-based assessment of surgeon skills",
    "Authors": "Kiyasseh et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "None",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "GB",
    "Country of Researchers": "CN, GB, US",
    "DOI": "https://doi.org/10.1038/s41746-023-00805-y",
    "Title": "An adversarial training framework for mitigating algorithmic biases in clinical machine learning",
    "Authors": "Yang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1038/s41746-022-00745-z",
    "Title": "A “one-size-fits-most” walking recognition method for smartphones, smartwatches, and wearable accelerometers",
    "Authors": "Straczkiewicz et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US, France",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.1145/3625007.3627336",
    "Title": "Discovering ideological structures in representation learning spaces in recommender systems on social media data",
    "Authors": "Faverjon and Ramaciotti",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Filter bubble, Information quality, News distribution, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3625007.3627724",
    "Title": "Evaluating Content Exposure Bias in Social Networks",
    "Authors": "Bartley et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "uClassify, Readable, HackerFactor, ChatGPT",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "India",
    "DOI": "https://doi.org/10.1145/3625007.3627324",
    "Title": "Auditing Gender Analyzers on Text Data",
    "Authors": "Jaiswal et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Organization: ",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Brazil",
    "DOI": "https://doi.org/10.1001/jamanetworkopen.2023.41625",
    "Title": "Fairness of Machine Learning Algorithms for Predicting Foregone Preventive Dental Care for Adults",
    "Authors": "Schuch et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Home Mortgage Disclosure Act",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "Israel",
    "Country of Researchers": "Israel",
    "DOI": "https://doi.org/10.1146/annurev-financial-110921-125930",
    "Title": "Algorithmic Fairness",
    "Authors": "Das et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Upstart",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Price discrimination, Information quality",
    "Method": "Direct scrape",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/0308518X231174026",
    "Title": "Banking on alternative credit scores: Auditing the calculative infrastructure of U.S. consumer lending",
    "Authors": "McCanless",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Amazon",
    "Behavior": "Exploitation",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, US, US",
    "DOI": "https://doi.org/10.1145/3610209",
    "Title": "Sociotechnical Audits: Broadening the Algorithm Auditing Lens to Investigate Targeted Advertising",
    "Authors": "Lam et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Denmark, Netherlands",
    "Country of Researchers": "Denmark, Netherlands",
    "DOI": "https://doi.org/10.1145/3604915.3608825",
    "Title": "Collaborative filtering algorithms are prone to mainstream-taste bias",
    "Authors": "Analytis and Hager",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1093/ccc/tcad015",
    "Title": "Using racial discourse communities to audit personalization algorithms",
    "Authors": "Stoldt et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, UK, Netherlands",
    "DOI": "https://doi.org/10.1007/s10618-022-00910-8",
    "Title": "Social norm bias: residual harms of fairness-aware algorithms",
    "Authors": "Cheng et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3600211.3604752",
    "Title": "Evaluation of targeted dataset collection on racial equity in face recognition",
    "Authors": "Hong",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3600211.3604707",
    "Title": "When Fair Classification Meets Noisy Protected Attributes",
    "Authors": "Ghosh et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "OpenAI, Azure",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Information quality",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3600211.3604712",
    "Title": "Supporting Human-AI Collaboration in Auditing LLMs with LLMs",
    "Authors": "Rastogi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Meta",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, Price discrimination, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3580305.3599916",
    "Title": "Towards Fairness in Personalized Ads Using Impression Variance Aware Reinforcement Learning",
    "Authors": "Timmaraju et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "LinkedIn Inc.",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), User profiling, Personalization",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1145/3580305.3599462",
    "Title": "Path-Specific Counterfactual Fairness for Recommender Systems",
    "Authors": "Zhu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICSE48619.2023.00136",
    "Title": "Information-Theoretic Testing and Debugging of Fairness Defects in Deep Neural Networks",
    "Authors": "Monjezi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Trillium Health Partners; Princess Margaret Cancer Centre; L'Institut Mutualiste Montsouris; Jules Bordet Institute",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Canada, France, Belgium",
    "Country of Researchers": "Canada, France, Belgium",
    "DOI": "https://doi.org/10.1016/S2589-7500(23)00067-5",
    "Title": "Development, multi-institutional external validation, and algorithmic audit of an artificial intelligence-based Side-specific Extra-Prostatic Extension Risk Assessment tool (SEPERA) for patients undergoing radical prostatectomy: a retrospective cohort study",
    "Authors": "Kwong et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "LUCID",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Belgium, UK, US",
    "DOI": "https://doi.org/10.1609/aaai.v37i12.26683",
    "Title": "LUCID: Exposing Algorithmic Bias through Inverse Design",
    "Authors": "Mazijn et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Organization not explicitly mentioned in the provided text.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1001/jamanetworkopen.2023.18495",
    "Title": "Racial and Ethnic Bias in Risk Prediction Models for Colorectal Cancer Recurrence When Race and Ethnicity Are Omitted as Predictors",
    "Authors": "Khor et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender misrepresentation, User categorization, User profiling",
    "Method": "Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "IN",
    "Country of Researchers": "US, IN",
    "DOI": "https://doi.org/10.1145/3593013.3593987",
    "Title": "In her Shoes: Gendered Labelling in Crowdsourced Safety Perceptions Data from India",
    "Authors": "Sengupta et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Child Protective Services",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "NLP",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3593013.3594094",
    "Title": "Examining risks of racial biases in NLP tools for child protective services",
    "Authors": "Field et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "bank, resource allocator",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "Austria",
    "Country of Researchers": "Austria",
    "DOI": "https://doi.org/10.1145/3593013.3594028",
    "Title": "Runtime Monitoring of Dynamic Fairness Properties",
    "Authors": "Henzinger et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Police",
    "Behavior": "Discrimination",
    "Specific Behavior": "Surveillance, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1145/3593013.3594084",
    "Title": "A Sociotechnical Audit: Assessing Police Use of Facial Recognition",
    "Authors": "Radiya-Dixit and Neff",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Multiple universities (no specific name mentioned)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US, Canada",
    "Country of Researchers": "US, Canada",
    "DOI": "https://doi.org/10.1145/3593013.3594107",
    "Title": "Cross-Institutional Transfer Learning for Educational Models: Implications for Model Performance, Fairness, and Equity",
    "Authors": "Gardner et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Austrian public employment service",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Austria",
    "Country of Researchers": "Austria, United States",
    "DOI": "https://doi.org/10.1145/3593013.3594120",
    "Title": "Bias as Boundary Object: Unpacking The Politics Of An Austerity Algorithm Using Bias Frameworks",
    "Authors": "Grill et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3593013.3594034",
    "Title": "How Redundant are Redundant Encodings? Blindness in the Wild and Racial Disparity when Race is Unobserved",
    "Authors": "Cheng et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Dexer",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, IL",
    "Country of Researchers": "Israel, US",
    "DOI": "https://doi.org/10.1145/3555041.3589725",
    "Title": "Dexer: Detecting and Explaining Biased Representation in Ranking",
    "Authors": "Moskovitch et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.compenvurbsys.2023.101967",
    "Title": "Auditing the fairness of place-based crime prediction models implemented with deep learning approaches",
    "Authors": "Wu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Fairguard",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Discrimination (other), Information quality",
    "Method": "Direct scrape",
    "Domain": "Smart Cities",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3576842.3582371",
    "Title": "Fairguard: Harness Logic-based Fairness Rules in Smart Cities",
    "Authors": "Zhao et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "bank",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "Serbia",
    "Country of Researchers": "Serbia",
    "DOI": "https://doi.org/10.1111/itor.13059",
    "Title": "A fair classifier chain for multi-label bank marketing strategy classification",
    "Authors": "Radovanović et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Amazon, Etsy",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, IE",
    "Country of Researchers": "US, IE",
    "DOI": "https://doi.org/10.1145/3543873.3587577",
    "Title": "Fairness-aware Differentially Private Collaborative Filtering",
    "Authors": "Yang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Apple Card",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3544548.3582074",
    "Title": "Participation and Division of Labor in User-Driven Algorithm Audits: How Do Everyday Users Work together to Surface Algorithmic Harms?",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Social Media Platforms",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling, Information quality, News distribution, Personalization",
    "Method": "Direct scrape, Sock puppets, Carrier puppet, Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US, EU",
    "Country of Researchers": "US, Germany, Netherlands",
    "DOI": "https://doi.org/10.1145/3579610",
    "Title": "Having your Privacy Cake and Eating it Too: Platform-supported Auditing of Social Media Algorithms for Public Interest",
    "Authors": "Imana et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "United States criminal justice system",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, China",
    "DOI": "https://doi.org/10.1093/jrsssa/qnad010",
    "Title": "Experimental evaluation of algorithm-assisted human decision-making: application to pretrial public safety assessment",
    "Authors": "Imai et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1016/j.patrec.2023.03.014",
    "Title": "Causal reasoning for algorithmic fairness in voice controlled cyber-physical systems",
    "Authors": "Fenu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Mapping",
    "Language": "English",
    "Country Studied": "Belgium, Greece, Finland",
    "Country of Researchers": "Belgium, Greece, Finland",
    "DOI": "https://doi.org/10.48786/edbt.2023.41",
    "Title": "Auditing for Spatial Fairness",
    "Authors": "Sacharidis et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Sweden",
    "Country of Researchers": "Sweden",
    "DOI": "https://doi.org/10.1145/3568294.3580032",
    "Title": "How Did We Miss This? A Case Study on Unintended Biases in Robot Social Behavior",
    "Authors": "Parreira et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Algorithmic bias, Data bias, User profiling",
    "Method": "Code",
    "Domain": "Cybersecurity",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3545947.3576302",
    "Title": "Incorporating the Concept of Bias and Fairness in Cybersecurity Curricular Module",
    "Authors": "Islam et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "OpenAI",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English, Spanish",
    "Country Studied": "New Zealand",
    "Country of Researchers": "New Zealand",
    "DOI": "https://doi.org/10.3390/socsci12030148",
    "Title": "The Political Biases of ChatGPT",
    "Authors": "Rozado",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "France",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.3390/a16030174",
    "Title": "How Optimal Transport Can Tackle Gender Biases in Multi-Class Neural Network Classifiers for Job Recommendations",
    "Authors": "Jourdan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "ChestXpert, MIMIC-CXR",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1016/j.ebiom.2023.104467",
    "Title": "Algorithmic encoding of protected characteristics in chest X-ray disease detection models",
    "Authors": "Glocker et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Oregon Child Welfare",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.childyouth.2022.106777",
    "Title": "The pursuit of algorithmic fairness: On “Correcting” algorithmic unfairness in a child welfare reunification success classifier",
    "Authors": "Purdy and Glass",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "University of Florida Health system/Shands Hospital",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3389/fdgth.2022.970281",
    "Title": "Fairness in the prediction of acute postoperative pain using machine learning models",
    "Authors": "Davoudi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1007/978-3-031-37745-7_9",
    "Title": "The Effect of Model Compression on Fairness in Facial Expression Recognition",
    "Authors": "Stoychev and Gunes",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Pregnancy Risk Assessment Monitoring System (PRAMS)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICMLA58977.2023.00154",
    "Title": "The Impact of Racial Disparities on Prenatal Care Adequacy: An Algorithmic Fairness Perspective",
    "Authors": "Pourbehzadi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Germany, US",
    "Country of Researchers": "Germany, US",
    "DOI": "https://doi.org/10.1109/BigData59044.2023.10386485",
    "Title": "Locating disparities in machine learning",
    "Authors": "von Zahn et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.18653/v1/2023.emnlp-main.579",
    "Title": "Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection",
    "Authors": "Raman et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "United Arab Emirates",
    "Country of Researchers": "United Arab Emirates, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181798926&partnerID=40&md5=cd62e797d7cbcb22fef4c1215de22f2d",
    "Title": "Building A Face Database Of Arab Faces Toward Evaluating Bias In Facial Analysis Systems",
    "Authors": "Khalil et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICHI57859.2023.00129",
    "Title": "Algorithmic Bias in De-Identification Tools",
    "Authors": "Heider",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICHI57859.2023.00043",
    "Title": "Quantification of Racial Disparity on Urinary Tract Infection Recurrence and Treatment Resistance in Florida using Algorithmic Fairness Methods",
    "Authors": "Jun et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "JP",
    "Country of Researchers": "JP",
    "DOI": "https://doi.org/10.5281/zenodo.10117682",
    "Title": "Examining Algorithmic Fairness for First-Term College Grade Prediction Models Relying on Pre-matriculation Data",
    "Authors": "Yanagiura et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "AWS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICCV51070.2023.00459",
    "Title": "Benchmarking Algorithmic Bias in Face Recognition: An Experimental Approach Using Synthetic Faces and Human Evaluation",
    "Authors": "Liang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178608717&partnerID=40&md5=9a27f0330b95676e1d19125c47397943",
    "Title": "Fairness Auditing, Explanation and Debiasing in Linguistic Data and Language Models",
    "Authors": "Marchiori Manerba",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "French Public Employment Service (PES)",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "FR, GB",
    "Country of Researchers": "FR, GB, UK",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177039056&partnerID=40&md5=aec84798e2d46e1669036788191dfa99",
    "Title": "Fairness in job recommendations: estimating, explaining, and reducing gender gaps",
    "Authors": "Bied et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Food and Drug Administration",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-43898-1_43",
    "Title": "Data AUDIT: Identifying Attribute Utility- and Detectability-Induced Bias in Task Models",
    "Authors": "Pavlak et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Austria",
    "Country of Researchers": "Austria",
    "DOI": "https://doi.org/10.1007/978-3-031-44267-4_15",
    "Title": "Monitoring Algorithmic Fairness Under Partial Observations",
    "Authors": "Henzinger et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "AU, AE",
    "Country of Researchers": "AU, AE, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174489515&partnerID=40&md5=cbae1c7904412e3a0497c7e210a160cb",
    "Title": "Promoting Fairness in Classification of Quality of Medical Evidence",
    "Authors": "Suster et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "DeepDerm",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Saudi Arabia",
    "DOI": "https://doi.org/10.1109/MIPR59079.2023.00030",
    "Title": "Toward Fairness Across Skin Tones in Dermatological Image Processing",
    "Authors": "Almuzainit et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Chile",
    "DOI": "https://doi.org/10.1007/978-3-031-33374-3_39",
    "Title": "Estimating the Risk of Individual Discrimination of Classifiers",
    "Authors": "Vasquez et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "IN, DE, GB",
    "Country of Researchers": "IN, DE, GB",
    "DOI": "https://doi.org/10.1007/978-3-031-40177-0_14",
    "Title": "Group Fairness in Case-Based Reasoning",
    "Authors": "Mitra et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Group misrepresentation, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.14778/3611479.3611525",
    "Title": "Through the Fairness Lens: Experimental Analysis and Evaluation of Entity Matching",
    "Authors": "Shahbazi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Netherlands, Italy",
    "Country of Researchers": "Netherlands, Italy",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171200321&partnerID=40&md5=87f68f009bcfd04797037efa18ea1fdd",
    "Title": "Assessing Fairness in Open-Source Face Mask Detection Algorithms",
    "Authors": "Zullich and Santacatterina",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Meta Ai",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US, Brazil, India, Indonesia, Mexico, Vietnam, Philippines",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/CVPRW59228.2023.00006",
    "Title": "The Casual Conversations v2 Dataset : A diverse, large benchmark for measuring fairness and robustness in audio/vision/speech models",
    "Authors": "Porgali et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Depresjon, Psykose, D-Vlog",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "UK, TR",
    "Country of Researchers": "UK, TR",
    "DOI": "https://doi.org/10.24963/ijcai.2023/658",
    "Title": "Towards Gender Fairness for Mental Health Prediction",
    "Authors": "Cheong et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "German public employment services",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168310944&partnerID=40&md5=b6edf3d6c45cdeaa835c02d862bd8738",
    "Title": "When Small Decisions Have Big Impact: Fairness Implications of Algorithmic Profiling Schemes",
    "Authors": "Kern et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "European public employment service",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Europe",
    "Country of Researchers": "Netherlands, Portugal",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168307504&partnerID=40&md5=a5a5ce5444d94396e8a0587c8c107e48",
    "Title": "How Differential Robustness Creates Disparate Impact: A European Case Study",
    "Authors": "Wan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Information quality",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Israel",
    "DOI": "https://doi.org/10.1109/ICDE55515.2023.00168",
    "Title": "Detection of Groups with Biased Representation in Ranking",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Singapore, US, Netherlands",
    "Country of Researchers": "Singapore, US, Netherlands",
    "DOI": "https://doi.org/10.21437/Interspeech.2023-1707",
    "Title": "Investigating model performance in language identification: beyond simple error statistics",
    "Authors": "Styles et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "None",
    "Behavior": "Discrimination",
    "Specific Behavior": "Filter bubble, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Netherlands",
    "Country of Researchers": "Netherlands",
    "DOI": "https://doi.org/10.1007/978-3-031-28276-8_7",
    "Title": "The Effect of Link Recommendation Algorithms on Network Centrality Disparities",
    "Authors": "Debono and Santos",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1007/978-3-031-23618-1_32",
    "Title": "Exposing Racial Dialect Bias in Abusive Language Detection: Can Explainability Play a Role?",
    "Authors": "Marchiori Manerba and Morini",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1109/ACCESS.2023.3252370",
    "Title": "Measuring Imbalance on Intersectional Protected Attributes and on Target Variable to Forecast Unfair Classifications",
    "Authors": "Mecati et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "BestCyte",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Canada",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1016/j.jpi.2022.100182",
    "Title": "BestCyte® primary screening of 500 ThinPrep Pap Test thin-layers: 3 Cytologists’ Interobserver diagnostic concordance with predicate manual microscopy relative to Truth Reference diagnoses defining NILM, ASCUS+, LSIL+, and ASCH+ thresholds for specificity, sensitivity, and equivalency grading",
    "Authors": "Chantziantoniou",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Beyond the AJR",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.2214/AJR.22.28053",
    "Title": "Beyond the AJR: Validation and Algorithmic Audit of a Deep Learning System to Detect Hip Fractures Radiographically",
    "Authors": "Stanborough and Garner",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "Slovenia, India, Brazil, Poland, Iran, Poland",
    "DOI": "https://doi.org/10.1109/TIFS.2022.3216468",
    "Title": "Exploring Bias in Sclera Segmentation Models: A Group Evaluation Approach",
    "Authors": "Vitek et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "D-BIAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/TVCG.2022.3209484",
    "Title": "D-BIAS: A Causality-Based Human-in-the-Loop System for Tackling Algorithmic Bias",
    "Authors": "Ghai and Mueller",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination",
    "Method": "Direct scrape",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "EU",
    "Country of Researchers": "Hungary",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-105026351319&partnerID=40&md5=342995039b16c5664a78c245cb03b3b7",
    "Title": "Pricing algorithms: algorithmic discrimination and collusive practices under EU competition law",
    "Authors": "Morbel",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Twitter",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Misinformation, Polarization, Information quality",
    "Method": "Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1145/3546915",
    "Title": "Using Agent-Based Modelling to Evaluate the Impact of Algorithmic Curation on Social Media",
    "Authors": "Gausen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "New Zealand",
    "Country of Researchers": "New Zealand",
    "DOI": "https://doi.org/10.3389/fcomp.2022.1070493",
    "Title": "Data and model bias in artificial intelligence for healthcare applications in New Zealand",
    "Authors": "Yogarajan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "IBM, Microsoft, Megvii, Amazon, Kairos",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Canada, US",
    "DOI": "https://doi.org/10.1145/3571151",
    "Title": "Actionable Auditing Revisited: - Investigating the Impact of Publicly Naming Biased Performance Results of Commercial AI Products",
    "Authors": "Raji and Buolamwini",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "IndieLabel",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, User categorization, User profiling",
    "Method": "Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3555625",
    "Title": "End-User Audits: A System Empowering Communities to Lead Large-Scale Investigations of Harmful Algorithmic Behavior",
    "Authors": "Lam et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3560905.3568433",
    "Title": "Discovering and Understanding Algorithmic Biases in Autonomous Pedestrian Trajectory Predictions",
    "Authors": "Bae and Xu",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1161/CIRCHEARTFAILURE.122.009473",
    "Title": "Improving Fairness in the Prediction of Heart Failure Length of Stay and Mortality by Integrating Social Determinants of Health",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Humantic AI\nCrystal",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User profiling, User categorization, Personalization, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1007/s10618-022-00861-0",
    "Title": "An external stability audit framework to test the validity of personality prediction in AI hiring",
    "Authors": "Rhea et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "eCoaching",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Personalization",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1007/s11257-022-09339-6",
    "Title": "Fair performance-based user recommendation in eCoaching systems",
    "Authors": "Boratto et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Meta",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "CN",
    "Country of Researchers": "CN",
    "DOI": "https://doi.org/10.1109/TPAMI.2021.3103191",
    "Title": "Meta Balanced Network for Fair Face Recognition",
    "Authors": "Wang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "...",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3389/feduc.2022.881449",
    "Title": "Racial, skin tone, and sex disparities in automated proctoring software",
    "Authors": "Yoder-Himes et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "FairDEA",
    "Behavior": "Discrimination",
    "Specific Behavior": "Disparate impact, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Serbia",
    "Country of Researchers": "Serbia",
    "DOI": "https://doi.org/10.1016/j.ejor.2021.12.001",
    "Title": "FairDEA—Removing disparate impact from efficiency scores",
    "Authors": "Radovanović et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "PhysioNet Challenge",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1016/j.jelectrocard.2022.07.007",
    "Title": "Age, sex and race bias in automated arrhythmia detectors",
    "Authors": "Perez-Alday et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Global news and media organization",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Global",
    "Country of Researchers": "Finland, Germany, United Kingdom",
    "DOI": "https://doi.org/10.1089/big.2021.0177",
    "Title": "Big Data, Small Personas: How Algorithms Shape the Demographic Representation of Data-Driven User Segments",
    "Authors": "Salminen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Humantic AI\nCrystal",
    "Behavior": "Distortion, Misjudgement",
    "Specific Behavior": "User profiling, Personalization, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3514094.3534189",
    "Title": "Resume Format, LinkedIn URLs and Other Unexpected Influences on AI Personality Prediction in Hiring: Results of an Audit",
    "Authors": "Rhea et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "AirBnB",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other), Harmful content",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3514094.3534160",
    "Title": "FINS auditing framework: Group fairness for subset selections",
    "Authors": "Cachel and Rundensteiner",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Facebook, Twitter, TikTok, Google, Apple",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, News distribution, Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3514094.3539538",
    "Title": "Inspecting Algorithmic Flows: Ethics, Transparency, and Accountability for Digital Mass Communication Platforms",
    "Authors": "Bandy",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1145/3514094.3534170",
    "Title": "Investigating Debiasing Effects on Classification and Explainability",
    "Authors": "Marchiori Manerba and Guidotti",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, UK",
    "Country of Researchers": "Iran, Netherlands, US, UK",
    "DOI": "https://doi.org/10.1145/3477495.3531718",
    "Title": "Experiments on Generalizability of User-Oriented Fairness in Recommender Systems",
    "Authors": "Rahmani et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Netflix",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, Personalization, Group misrepresentation",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "Spanish",
    "Country Studied": "Mexico",
    "Country of Researchers": "Mexico",
    "DOI": "https://doi.org/10.12804/revistas.urosario.edu.co/disertaciones/a.10616",
    "Title": "A Netflix Geography of Mexico: Automatized Recommendations and Content Supplied Diversity; Uma geografia do México na Netflix: recomendações automatizadas e diversidade de conteúdo oferecido; UNA GEOGRAFÍA DE MÉXICO EN NETFLIX: RECOMENDACIONES AUTOMATIZADAS Y DIVERSIDAD DE CONTENIDOS OFERTADOS",
    "Authors": "Sued",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Transport Behavioural Modelling",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain, Belgium",
    "DOI": "https://doi.org/10.3390/su14148416",
    "Title": "Fair Models for Impartial Policies: Controlling Algorithmic Bias in Transport Behavioural Modelling",
    "Authors": "Vega-Gonzalo and Christidis",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Organization not explicitly mentioned",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1093/jamia/ocac052",
    "Title": "Assessing socioeconomic bias in machine learning algorithms in health care: A case study of the HOUSES index",
    "Authors": "Juhn et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "IRS, United States Internal Revenue Service",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other), Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1145/3531146.3533204",
    "Title": "Algorithmic Fairness and Vertical Equity: Income Fairness with IRS Tax Audit Models",
    "Authors": "Black et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender bias, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.2196/34366",
    "Title": "Fairness in Mobile Phone–Based Mental Health Assessment Algorithms: Exploratory Study",
    "Authors": "Park et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "iSecureHome",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, Surveillance, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "India",
    "Country of Researchers": "India, China, US",
    "DOI": "https://doi.org/10.1016/j.asoc.2022.108788",
    "Title": "iSecureHome: A deep fusion framework for surveillance of smart homes using real-time emotion recognition",
    "Authors": "Kaushik et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany, Switzerland",
    "DOI": "https://doi.org/10.1007/s12599-021-00716-w",
    "Title": "The Cost of Fairness in AI: Evidence from E-Commerce",
    "Authors": "von Zahn et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Exploitation",
    "Specific Behavior": "Price discrimination",
    "Method": "Direct scrape",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "China",
    "Country of Researchers": "China",
    "DOI": "https://doi.org/10.3389/fpsyg.2022.825420",
    "Title": "The Impact of Algorithmic Price Discrimination on Consumers’ Perceived Betrayal",
    "Authors": "Wu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1016/S2589-7500(22)00003-6",
    "Title": "The medical algorithmic audit",
    "Authors": "Liu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Royal Adelaide Hospital, Stanford University Medical Center",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "Australia, USA",
    "Country of Researchers": "Australia, USA",
    "DOI": "https://doi.org/10.1016/S2589-7500(22)00004-8",
    "Title": "Validation and algorithmic audit of a deep learning system for the detection of proximal femoral fractures in patients in the emergency department: a diagnostic accuracy study",
    "Authors": "Oakden-Rayner et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3491102.3501831",
    "Title": "How Child Welfare Workers Reduce Racial Disparities in Algorithmic Decisions",
    "Authors": "Cheng et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Washington Assessment of Risk Model (WARM)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Canada",
    "DOI": "https://doi.org/10.1145/3491101.3519771",
    "Title": "How to Train a (Bad) Algorithmic Caseworker: A Quantitative Deconstruction of Risk Assessments in Child Welfare",
    "Authors": "Saxena et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "South Korea",
    "Country of Researchers": "South Korea",
    "DOI": "https://doi.org/10.1145/3485447.3512244",
    "Title": "Fairness Audit of Machine Learning Models with Confidential Computing",
    "Authors": "Park et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "King.com Ltd",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "SE, GR",
    "Country of Researchers": "SE, GR, IE",
    "DOI": "https://doi.org/10.1145/3485447.3512249",
    "Title": "Link Recommendations for PageRank Fairness",
    "Authors": "Tsioutsiouliklis et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Organization not explicitly mentioned",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1136/bmjhci-2021-100460",
    "Title": "Evaluating algorithmic fairness in the presence of clinical guidelines: The case of atherosclerotic cardiovascular disease risk estimation",
    "Authors": "Foryciarz et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Spain",
    "Country of Researchers": "Spain, Germany",
    "DOI": "https://doi.org/10.1016/j.artint.2022.103682",
    "Title": "Sensitive loss: Improving accuracy and fairness of face representations with discrimination-aware deep learning",
    "Authors": "Serna et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.1145/3490100.3516457",
    "Title": "Inequity in Popular Speech Recognition Systems for Accented English Speech",
    "Authors": "Ike et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Personalization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1073/pnas.2115293119",
    "Title": "Eliminating unintended bias in personalized policies using bias-eliminating adapted trees (BEAT)",
    "Authors": "Ascarza and Israeli",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Last.fm",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, Austria",
    "Country of Researchers": "Austria, Germany",
    "DOI": "https://doi.org/10.1145/3498366.3505791",
    "Title": "LFM-2b: A dataset of enriched music listening events for recommender systems research and fairness analysis",
    "Authors": "Schedl et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "NL, US",
    "Country of Researchers": "NL",
    "DOI": "https://doi.org/10.3390/jcp2010011",
    "Title": "Association Rule Mining Meets Regression Analysis: An Automated Approach to Unveil Systematic Biases in Decision-Making Processes",
    "Authors": "Genga et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, Singapore, Canada, US",
    "DOI": "https://doi.org/10.1126/sciadv.abj1812",
    "Title": "Cross-ethnicity/race generalization failure of behavioral prediction from resting-state functional connectivity",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Web of Science",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Canada, US, Germany",
    "DOI": "https://doi.org/10.1371/journal.pone.0264270",
    "Title": "Avoiding bias when inferring race using name-based approaches",
    "Authors": "Kozlowski et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Dolby Laboratories",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "ES, US",
    "Country of Researchers": "ES, US, BE",
    "DOI": "https://doi.org/10.1145/3488560.3498397",
    "Title": "Assessing algorithmic biases for musical version identification",
    "Authors": "Yesiler et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Danish unemployment services agency",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "DK",
    "Country of Researchers": "DK",
    "DOI": "https://doi.org/10.1145/3492827",
    "Title": "Auditing Risk Prediction of Long-Term Unemployment",
    "Authors": "Seidelin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "Portugal, US",
    "Country of Researchers": "US, Hong Kong",
    "DOI": "https://doi.org/10.1109/TALE54877.2022.00058",
    "Title": "Algorithmic Bias in a Student Success Prediction Models: Two Case Studies",
    "Authors": "Xiang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163208410&partnerID=40&md5=1221f1dc92119b801f6696683314361d",
    "Title": "Robustness Disparities in Face Detection",
    "Authors": "Dooley et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US, Canada",
    "Country of Researchers": "United Kingdom, Canada",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162158632&partnerID=40&md5=f941710264fbe21ca105b3132dbc7428",
    "Title": "Washing The Unwashable: On The (Im)possibility of Fairwashing Detection",
    "Authors": "Shamsabadi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ISTAS55053.2022.10227135",
    "Title": "Age Bias: A Tremendous Challenge for Algorithms in the Job Candidate Screening Process",
    "Authors": "Harris",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.48009/2_iis_2022_107",
    "Title": "A black box approach to auditing algorithms",
    "Authors": "Lee",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "COMPAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICDMW58026.2022.00027",
    "Title": "Equal Confusion Fairness: Measuring Group-Based Disparities in Automated Decision Systems",
    "Authors": "Gursoy and Kakadiaris",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "CIKM 2022 EvalRS Challenge",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146236032&partnerID=40&md5=cc075d37353568b54dff472678be6c70",
    "Title": "Bias mitigation in recommender systems to improve diversity",
    "Authors": "Cheng et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1007/978-3-031-23223-7_2",
    "Title": "Disproportionate Subgroup Impacts and Other Challenges of Fairness in Artificial Intelligence for Medical Image Analysis",
    "Authors": "Stanley et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling, Personalization",
    "Method": "Direct scrape",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144053011&partnerID=40&md5=fd00ed2b9bb7f71aa964200b0526d70e",
    "Title": "Targeted Ads and/as Racial Discrimination: Exploring Trends in New York City Ads for College Scholarships",
    "Authors": "Chang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "Australia",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.1109/ISTAS55053.2022.10227106",
    "Title": "Gender Bias in AI Recruitment Systems: A Sociological-and Data Science-based Case Study",
    "Authors": "Njoto et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Gender API, Namsor, Genderize.io",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender Bias, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.7560/IC57303",
    "Title": "Gender Bias in Big Data Analysis",
    "Authors": "Misa",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "AWS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-19778-9_17",
    "Title": "Unsupervised and Semi-supervised Bias Benchmarking in Face Recognition",
    "Authors": "Chouldechova et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling, Harmful content, Information quality, News distribution",
    "Method": "Direct scrape, Sock puppets, Carrier puppet",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.4324/9781003170884-18",
    "Title": "AD ACCOUNTABILITY ONLINE: A methodological approach",
    "Authors": "Andrejevic et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": " ",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.5220/0010962100003182",
    "Title": "Fairness of In-session Dropout Prediction",
    "Authors": "Rzepka et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Moodle",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling, Information quality",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.5220/0010998900003182",
    "Title": "Introducing a Framework for Code based Fairness Audits of Learning Analytics Systems on the Example of Moodle Learning Analytics",
    "Authors": "Tagharobi and Simbeck",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "UK police force",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring, Social Media",
    "Language": "English",
    "Country Studied": "GB",
    "Country of Researchers": "ES, GB",
    "DOI": "https://doi.org/10.5093/pi2022a11",
    "Title": "Predicting Domestic Abuse (Fairly) and Police Risk Assessment; La predicción (equitativa) de la violencia doméstica y la evaluación policial de riesgo",
    "Authors": "Turner et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "NL",
    "Country of Researchers": "NL, US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139592377&partnerID=40&md5=b73f86621c02bb3f0b50c9c2048df358",
    "Title": "Closing the Gender Wage Gap: Adversarial Fairness in Job Recommendation",
    "Authors": "Rus et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "German credit data set",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Information quality",
    "Method": "Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "NL",
    "DOI": "https://doi.org/10.1007/978-3-031-15791-2_17",
    "Title": "PEBAM: A Profile-Based Evaluation Method for Bias Assessment on Mixed Datasets",
    "Authors": "Wilms et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Open University",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Information quality",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.18420/delfi2022-025",
    "Title": "Data Leakage Through Click Data in Virtual Learning Environments",
    "Authors": "Hartmann et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content, Information quality, News distribution, Personalization, User profiling",
    "Method": "Sock puppets",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Slovakia, Czech Republic",
    "DOI": "https://doi.org/10.24963/ijcai.2022/749",
    "Title": "Black-box Audit of YouTube's Video Recommendation: Investigation of Misinformation Filter Bubble Dynamics (Extended Abstract)",
    "Authors": "Tomlein et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-031-11647-6_12",
    "Title": "Exploring Fairness in Automated Grading and Feedback Generation of Open-Response Math Problems",
    "Authors": "Gurung and Heffernan",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Open University",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "Hungary, Slovakia",
    "DOI": "https://doi.org/10.1109/ICICS55353.2022.9811127",
    "Title": "Should Course-based At-risk Predication Models Include Protected Features?",
    "Authors": "Jawthari and Stoffova",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Popularity bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, UK, Iran",
    "DOI": "https://doi.org/10.1007/978-3-031-09316-6_7",
    "Title": "The Unfairness of Popularity Bias in Book Recommendation",
    "Authors": "Naghiaei et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Chile",
    "Country of Researchers": "Spain, Chile",
    "DOI": "https://doi.org/10.1007/978-3-031-09316-6_9",
    "Title": "Analysis of Biases in Calibrated Recommendations",
    "Authors": "Rojas et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Distortion",
    "Specific Behavior": "Popularity bias, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "AT, US",
    "Country of Researchers": "AT",
    "DOI": "https://doi.org/10.1007/978-3-031-09316-6_1",
    "Title": "Popularity Bias in Collaborative Filtering-Based Multimedia Recommender Systems",
    "Authors": "Kowald and Lacic",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Uber, Lyft, Via",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Germany",
    "DOI": "https://doi.org/10.1007/978-3-030-95346-1_137",
    "Title": "If I Tap It, Will They Come? An Introductory Analysis of Fairness in a Large-Scale Ride Hailing Dataset: An Abstract",
    "Authors": "Caliskan and Kaplan",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Deliveroo Italy S.r.l.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "Italian",
    "Country Studied": "IT",
    "Country of Researchers": "Italy",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131332249&partnerID=40&md5=64f79276c24ee852c8d54c91840f211b",
    "Title": "ALGORITHMIC DISCRIMINATION AND WORKERS’ RIGHTS: THE ORDER OF THE TRIBUNAL OF BOLOGNA; Discriminazioni algoritmiche e tutela dei lavoratori: Riflessioni a partire dall’Ordinanza del Tribunale di Bologna del 31 dicembre 2020",
    "Authors": "Borzaga and Mazzetti",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Pennsylvania",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/20539517221094002",
    "Title": "Carceral algorithms and the history of control: An analysis of the Pennsylvania additive classification tool",
    "Authors": "Massaro et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, UK, Canada",
    "Country of Researchers": "UK, US, Canada",
    "DOI": "https://doi.org/10.1007/978-3-030-99736-6_43",
    "Title": "Revisiting Popularity and Demographic Biases in Recommender Evaluation and Effectiveness",
    "Authors": "Neophytou et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Norway",
    "Country of Researchers": "Norway",
    "DOI": "https://doi.org/10.1109/WACVW54805.2022.00047",
    "Title": "Algorithmic Fairness in Face Morphing Attack Detection",
    "Authors": "Ramachandra et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Nigeria",
    "Country of Researchers": "Nigeria, US",
    "DOI": "https://doi.org/10.1109/WACVW54805.2022.00048",
    "Title": "Similarities in African Ethnic Faces from the Biometric Recognition Viewpoint",
    "Authors": "Iloanusi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "FairRankVis",
    "Behavior": "Distortion",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, China, Netherlands",
    "DOI": "https://doi.org/10.1109/TVCG.2021.3114850",
    "Title": "FairRankVis: A Visual Analytics Framework for Exploring Algorithmic Fairness in Graph Mining Models",
    "Authors": "Xie et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, Germany",
    "Country of Researchers": "Germany, US",
    "DOI": "https://doi.org/10.1016/j.ipm.2021.102707",
    "Title": "Fair Top-k Ranking with multiple protected groups",
    "Authors": "Zehlike et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Misinformation, Harmful content, News distribution, Personalization, User profiling",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3462204.3481788",
    "Title": "Identifying, Measuring and Contesting Algorithmically Curated Misinformation",
    "Authors": "Juneja",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Fujitsu, University of Southern California",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US, Japan",
    "Country of Researchers": "US, Japan",
    "DOI": "https://doi.org/10.1145/3461615.3485427",
    "Title": "Predicting Worker Accuracy from Nonverbal Behaviour: Benefits and Potential for Algorithmic Bias",
    "Authors": "Toyoda et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3462244.3479943",
    "Title": "What's Fair is Fair: Detecting and Mitigating Encoded Bias in Multimodal Models of Museum Visitor Attention",
    "Authors": "Acosta et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Gender bias, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1002/pra2.576",
    "Title": "Gendered Sounds in Household Devices: Results from an Online Search Case Study",
    "Authors": "Roy et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1145/3460418.3479343",
    "Title": "Data Portability as a Tool for Audit",
    "Authors": "Zwiebelmann and Henderson",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Commercial platform",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, User categorization, User profiling, Information quality",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Hong Kong",
    "Country of Researchers": "Hong Kong",
    "DOI": "https://doi.org/10.1145/3460231.3474244",
    "Title": "User bias in beyond-accuracy measurement of recommendation algorithms",
    "Authors": "Wang and Chen",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Siri",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, Personalization, User profiling",
    "Method": "Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85154053157&partnerID=40&md5=06df16cf04746597c0d955c2fb6fa7df",
    "Title": "Exploring Siri’s Content Diversity Using a Crowdsourced Audit",
    "Authors": "Glaesener",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Hiretual, Paradox, MyInterview, Textio, Traitify, HireVue, Cammio",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other), Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK, US",
    "DOI": "https://doi.org/10.3390/jintelligence9030046",
    "Title": "Systematizing audit in algorithmic recruitment",
    "Authors": "Kazim et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.3390/fi13090234",
    "Title": "A study of gender bias in face presentation attack and its mitigation",
    "Authors": "Alshareef et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "RisCanvi",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "ES",
    "DOI": "https://doi.org/10.1145/3462757.3466150",
    "Title": "Enhancing a recidivism prediction tool with machine learning: Effectiveness and algorithmic fairness",
    "Authors": "Karimi-Haghighi and Castillo",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3461702.3462623",
    "Title": "Towards Equity and Algorithmic Fairness in Student Grade Prediction",
    "Authors": "Jiang and Pardos",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "TaskRabbit",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, US",
    "DOI": "https://doi.org/10.1145/3461702.3462602",
    "Title": "Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and Algorithmic Biases in Online Hiring",
    "Authors": "Sühr et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://doi.org/10.1145/3461702.3462567",
    "Title": "Person, Human, Neither: The Dehumanization Potential of Automated Image Tagging",
    "Authors": "Barlas et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Organization not specified in abstract.",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "ES",
    "DOI": "https://doi.org/10.1145/3461702.3462600",
    "Title": "Comparing Equity and Effectiveness of Different Algorithms in an Application for the Room Rental Market",
    "Authors": "Solans et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Ridehailing",
    "Behavior": "Discrimination",
    "Specific Behavior": "Price discrimination, User profiling",
    "Method": "Direct scrape",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3461702.3462561",
    "Title": "Disparate Impact of Artificial Intelligence Bias in Ridehailing Economy's Price Discrimination Algorithms",
    "Authors": "Pandey and Caliskan",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User fairness, Item fairness, Diversity",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3471158.3472260",
    "Title": "User Fairness, Item Fairness, and Diversity for Rankings in Two-Sided Markets",
    "Authors": "Wang and Joachims",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other), Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3404835.3462850",
    "Title": "When Fair Ranking Meets Uncertain Inference",
    "Authors": "Ghosh et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "California",
    "Behavior": "Misjudgement",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Germany, Netherlands",
    "DOI": "https://doi.org/10.1016/j.chiabu.2021.105059",
    "Title": "Predicting youth at high risk of aging out of foster care using machine learning methods",
    "Authors": "Ahn et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Social Media Platforms",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Personalization, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Slovakia",
    "Country of Researchers": "Slovakia",
    "DOI": "https://doi.org/10.1145/3450614.3463353",
    "Title": "Towards Continuous Automatic Audits of Social Media Adaptive Behavior and its Role in Misinformation Spreading",
    "Authors": "Šimko et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "A large U.S. research university",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, US",
    "DOI": "https://doi.org/10.1145/3430895.3460139",
    "Title": "Should College Dropout Prediction Models Include Protected Attributes?",
    "Authors": "Yu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "COMPAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.4230/LIPIcs.FORC.2021.4",
    "Title": "A possibility in algorithmic fairness: Can calibration and equal error rates be reconciled?",
    "Authors": "Reich and Vijaykumar",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "Belgium",
    "Country of Researchers": "Spain, Belgium",
    "DOI": "https://doi.org/10.1007/s10506-020-09268-y",
    "Title": "Evaluating causes of algorithmic bias in juvenile criminal recidivism",
    "Authors": "Mirón et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "IBM",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1001/jamanetworkopen.2021.3909",
    "Title": "Comparison of Methods to Reduce Bias from Clinical Prediction Models of Postpartum Depression",
    "Authors": "Park et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Public Safety Assessment (PSA)",
    "Behavior": "Discrimination",
    "Specific Behavior": "User profiling, Surveillance, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1525/nclr.2021.24.2.156",
    "Title": "Evaluating algorithmic risk assessment",
    "Authors": "Hamilton",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1109/JBHI.2020.3019242",
    "Title": "A New Dataset for Facial Motion Analysis in Individuals with Neurological Disorders",
    "Authors": "Bandini et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "pymetrics",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3442188.3445928",
    "Title": "Building and auditing fair algorithms: A case study in candidate screening",
    "Authors": "Wilson et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Prosper.com",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User categorization, User profiling",
    "Method": "Direct scrape, Code, Crowdsourcing",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1287/isre.2020.0990",
    "Title": "Crowds, lending, machine, and bias",
    "Authors": "Fu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://doi.org/10.1145/3432931",
    "Title": "To See is to Stereotype",
    "Authors": "Barlas et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "ProPublica, COMPAS",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Brazil",
    "DOI": "https://doi.org/10.34190/EAIR.21.034",
    "Title": "Data Fairness to Find Biases That Influence the Algorithm's Decision Making Results",
    "Authors": "Soares and Silva",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "FairShades",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1109/CogMI52975.2021.00014",
    "Title": "FairShades: Fairness Auditing via Explainability in Abusive Language Detection Systems",
    "Authors": "Marchiori Manerba and Guidotti",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Instagram",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Personalization",
    "Method": "Sock puppets",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127629354&partnerID=40&md5=c5ccf5050aa080a17973287830e742ee",
    "Title": "DE-CODING INSTAGRAM AS A SPECTACLE: A CRITICAL ALGORITHM AUDIT ANALYSIS",
    "Authors": "Kollyri",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-030-78292-4_21",
    "Title": "A Fairness Evaluation of Automated Methods for Scoring Text Evidence Usage in Writing",
    "Authors": "Litman et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Australia",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.1007/978-3-030-78292-4_31",
    "Title": "Assessing Algorithmic Fairness in Automatic Classifiers of Educational Forum Posts",
    "Authors": "Sha et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "OpenCV",
    "Behavior": "Discrimination",
    "Specific Behavior": "Bias, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/BigMM52142.2021.00011",
    "Title": "Accuracy and Fairness in Pupil Detection Algorithm",
    "Authors": "Kulkarni et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-030-80387-2_7",
    "Title": "Assessing Bias in YouTube’s Video Recommendation Algorithm in a Cross-lingual and Cross-topical Context",
    "Authors": "Kirdemir et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "CLIP",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Thailand",
    "Country of Researchers": "Thailand",
    "DOI": "https://doi.org/10.1109/ACCESS.2021.3136898",
    "Title": "Implicit Stereotypes in Pre-Trained Classifiers",
    "Authors": "Dehouche",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Amazon, Facebook, Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119623451&partnerID=40&md5=45b4e19607b210f5f0644752e9e6aa82",
    "Title": "Disability discrimination using artificial intelligence systems and social scoring: Can we disable digital bias?",
    "Authors": "Geslevich Packin",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.17645/mac.v9i4.4184",
    "Title": "What’s “up next”? Investigating algorithmic recommendations on youtube across issues and over time",
    "Authors": "Matamoros-Fernández et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "DENOUNCER",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.14778/3476311.3476328",
    "Title": "Denouncer: Detection of unfairness in classifiers",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "CN",
    "Country of Researchers": "CN",
    "DOI": "https://doi.org/10.1109/ACCESS.2021.3122443",
    "Title": "An empirical study on group fairness metrics of judicial data",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Organization not explicitly mentioned in the abstract.",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, Personalization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "France",
    "Country of Researchers": "France, US",
    "DOI": "https://doi.org/10.1007/978-3-030-85613-7_22",
    "Title": "ObjectivAIze: Measuring Performance and Biases in Augmented Business Decision Systems",
    "Authors": "Baudel et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Amazon.com, Inc.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-030-74697-1_15",
    "Title": "Towards Causal Benchmarking of Biasin Face Analysis Algorithms",
    "Authors": "Balakrishnan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "IBM",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Netherlands, US",
    "DOI": "https://doi.org/10.1007/978-3-030-79460-6_11",
    "Title": "Disparate Impact Diminishes Consumer Trust Even for Advantaged Users",
    "Authors": "Draws et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://doi.org/10.1007/978-3-030-79840-6_12",
    "Title": "‘Expected Most of the Results, but Some Others..Surprised Me’: Personality Inference in Image Tagging Services",
    "Authors": "Kasinidou et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Harmful content, Information quality, Personalization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Search, Recommendation",
    "Language": "English",
    "Country Studied": "",
    "Country of Researchers": "",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111453671&partnerID=40&md5=1ac407fb78439054b73a610a217e2980",
    "Title": "2nd International Workshop on Algorithmic Bias in Search and Recommendation, BIAS 2021",
    "Authors": "",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, News distribution",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, United Kingdom",
    "DOI": "https://doi.org/10.1007/978-3-030-78818-6_13",
    "Title": "Crucial Challenges in Large-Scale Black Box Analyses",
    "Authors": "Krafft et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, Information quality, News distribution, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Europe",
    "Country of Researchers": "Europe",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107330830&partnerID=40&md5=8dee26866aee7a57020161987ea6eb35",
    "Title": "43rd European Conference on Information Retrieval, ECIR 2021",
    "Authors": "",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, User profiling",
    "Method": "Code",
    "Domain": "Language Processing",
    "Language": "English, French, Spanish",
    "Country Studied": "NL, FR, ES",
    "Country of Researchers": "NL, US",
    "DOI": "https://doi.org/10.18653/v1/2021.eacl-main.188",
    "Title": "Machine translationese: Effects of algorithmic bias on linguistic complexity in machine translation",
    "Authors": "Vanmassenhove et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "Google",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102991138&partnerID=40&md5=76ee8e4274154dbcf817b7f2397ab804",
    "Title": "Autocorrecting for whiteness",
    "Authors": "Dyal-Chand",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2021",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Greece",
    "Country of Researchers": "Greece",
    "DOI": "https://doi.org/10.1007/978-3-030-65351-4_49",
    "Title": "Applying Fairness Constraints on Graph Node Ranks Under Personalization Bias",
    "Authors": "Krasanakis et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Popularity bias, User categorization, User profiling, Harmful content",
    "Method": "Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US, Netherlands",
    "Country of Researchers": "Netherlands, US",
    "DOI": "https://doi.org/10.1145/3340531.3412152",
    "Title": "Feedback Loop and Bias Amplification in Recommender Systems",
    "Authors": "Mansoury et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Police Department",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3428502.3428503",
    "Title": "Is the data fair?: An assessment of the data quality of algorithmic policing systems",
    "Authors": "Udoh",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Popularity bias, User categorization, User profiling, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1145/3383313.3418487",
    "Title": "The Connection between Popularity Bias, Calibration, and Fairness in Recommendation",
    "Authors": "Abdollahpouri et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "User categorization, User profiling, Harmful content, Information quality",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3394486.3403080",
    "Title": "InFoRM: Individual Fairness on Graph Mining",
    "Authors": "Kang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "Cyprus",
    "Country of Researchers": "Cyprus",
    "DOI": "https://doi.org/10.1145/3386392.3399567",
    "Title": "Emotion-based Stereotypes in Image Analysis Services",
    "Authors": "Kyriakou et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender bias, User categorization",
    "Method": "Direct scrape",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3372923.3404804",
    "Title": "Man is to person as woman is to location: Measuring gender bias in named entity recognition",
    "Authors": "Mehrabi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code, Crowdsourcing",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3391403.3399545",
    "Title": "Biased Programmers? or Biased Data? A Field Experiment in Operationalizing AI Ethics",
    "Authors": "Cowgill et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Filter bubble, Personalization, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "ES, IT",
    "Country of Researchers": "ES, IT",
    "DOI": "https://doi.org/10.1145/3340631.3398669",
    "Title": "Hands on Data and Algorithmic Bias in Recommender Systems",
    "Authors": "Boratto and Marras",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3392874",
    "Title": "Exposing Error in Poverty Management Technology: A Method for Auditing Government Benefits Screening Tools",
    "Authors": "Escher and Banovic",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Miami-Dade County's criminal justice system",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/CRV50864.2020.00039",
    "Title": "It's Not Just Black and White: Classifying Defendant Mugshots Based on the Multidimensionality of Race and Ethnicity",
    "Authors": "Dass et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "RECAST",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, Information quality, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3403676.3403691",
    "Title": "RECAST: Interactive Auditing of Automatic Toxicity Detection Models",
    "Authors": "Wright et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Prosper.com",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3366424.3383557",
    "Title": "Fairness of Classification Using Users? Social Relationships in Online Peer-To-Peer Lending",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "FairSearch",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Information quality, News distribution, User profiling",
    "Method": "Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Germany",
    "Country of Researchers": "Germany, Spain, North Macedonia",
    "DOI": "https://doi.org/10.1145/3366424.3383534",
    "Title": "FairSearch: A Tool for Fairness in Ranked Search Results",
    "Authors": "Zehlike et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Harmful content, User categorization, User profiling, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "NZ",
    "Country of Researchers": "New Zealand",
    "DOI": "https://doi.org/10.1371/journal.pone.0231189",
    "Title": "Wide range screening of algorithmic bias in word embedding models using large sentiment lexicons reveals underreported bias types",
    "Authors": "Rozado",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Telef'nica Innovaci'n Alpha",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Crowdsourcing, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "ES, US",
    "Country of Researchers": "ES, US",
    "DOI": "https://doi.org/10.1145/3375627.3375852",
    "Title": "Auditing algorithms: On lessons learned and the risks of data minimization",
    "Authors": "Galdon-Clavell et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "DigitalStakeout",
    "Behavior": "Discrimination, Distortion",
    "Specific Behavior": "Surveillance, User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3351095.3372841",
    "Title": "Whose tweets are surveilled for the police: An audit of a social-media monitoring tool via log files",
    "Authors": "Borradaile et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Large public university",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Higher education",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, United States",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160007220&partnerID=40&md5=6068bf9d06a4e36f730b62b7874108b0",
    "Title": "Towards Accurate and Fair Prediction of College Success: Evaluating Different Sources of Student Data",
    "Authors": "Yu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Gambling operators",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "UK",
    "Country of Researchers": "UK",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108809471&partnerID=40&md5=b027d1ed6f63eebaadeb5b66ce4a26e9",
    "Title": "Lessons learned from problem gambling classification: indirect discrimination and algorithmic fairness",
    "Authors": "Percy et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Correctional Offender Management Profiling for Alternative Sanctions (COMPAS)",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106598872&partnerID=40&md5=42141d71714cb9329368c2f4665ae6a3",
    "Title": "Algorithmic Bias in Recidivism Prediction: A Causal Perspective",
    "Authors": "Khademi and Honavar",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Amazon.com, Inc.",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/978-3-030-58523-5_32",
    "Title": "Towards Causal Benchmarking of Bias in Face Analysis Algorithms",
    "Authors": "Balakrishnan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "ES, IT",
    "Country of Researchers": "ES, IT",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097199518&partnerID=40&md5=946368d2a4c8fb2940c0be4dc42cb3b8",
    "Title": "The effect of homophily on disparate visibility of minorities in people recommender systems",
    "Authors": "Fabbri et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Speech Recognition",
    "Language": "English",
    "Country Studied": "Italy",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1007/978-3-030-58811-3_6",
    "Title": "Exploring Algorithmic Fairness in Deep Speaker Verification",
    "Authors": "Fenu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Direct scrape",
    "Domain": "Education",
    "Language": "English",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091466727&partnerID=40&md5=6ba02e7986c47cba2e3e7d2d35f98613",
    "Title": "Fairness in learning analytics: Student at-risk prediction in virtual learning environments",
    "Authors": "Riazy et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Outside in",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "Mexico",
    "Country of Researchers": "Mexico",
    "DOI": "https://doi.org/10.7238/a.v0i26.3359",
    "Title": "Outside in : Exile at home. an algorithmic discrimination system; Outside in: Exile at home. un sistema de discriminación algorítmica",
    "Authors": "Castro",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, News distribution, Personalization",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089500384&partnerID=40&md5=c14977be0a425f8dd6642477b7939fb3",
    "Title": "The media coverage of the 2020 US presidential election candidates through the lens of google's top stories",
    "Authors": "Kawakami et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "YouTube",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, News distribution, User categorization",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/aaai.v34i09.7117",
    "Title": "Reasoning about political bias in content moderation",
    "Authors": "Jiang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Last.fm",
    "Behavior": "Discrimination",
    "Specific Behavior": "Popularity bias, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "AT, US",
    "Country of Researchers": "AT, US",
    "DOI": "https://doi.org/10.1007/978-3-030-45442-5_5",
    "Title": "The unfairness of popularity bias in music recommendation: A reproducibility study",
    "Authors": "Kowald et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "None",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "ES",
    "Country of Researchers": "ES, DE",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081638039&partnerID=40&md5=97d2e3cee332d446137e71191d93c4db",
    "Title": "Algorithmic discrimination: Formulation and exploration in deep learning-based face biometrics",
    "Authors": "Serna et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Social Media",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Personalization, Information quality, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "German",
    "Country Studied": "DE",
    "Country of Researchers": "DE",
    "DOI": "https://doi.org/10.1016/j.osnem.2019.100058",
    "Title": "Political communication on social media: A tale of hyperactive users and bias in recommender systems",
    "Authors": "Papakyriakopoulos et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "The Association of University Radiologists",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "IN",
    "Country of Researchers": "IN",
    "DOI": "https://doi.org/10.1016/j.acra.2019.09.009",
    "Title": "The Algorithmic Audit: Working with Vendors to Validate Radiology-AI Algorithms—How We Do It",
    "Authors": "Mahajan et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "PredPol",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "Criminal Justice",
    "Language": "English",
    "Country Studied": "US, FR",
    "Country of Researchers": "France",
    "DOI": "https://doi.org/10.23987/sts.66156",
    "Title": "Values and consequences in predictive machine evaluation. A sociology of predictive policing1",
    "Authors": "Benbouzid",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Facebook",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Advertising",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3359301",
    "Title": "Discrimination through optimization: How Facebook’s ad delivery can lead to biased outcomes",
    "Authors": "Ali et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1126/science.aax2342",
    "Title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "Authors": "Obermeyer et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3347447.3356751",
    "Title": "Toward fairness in face matching algorithms",
    "Authors": "Alasadi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Twitter",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3341161.3342949",
    "Title": "Fairness across network positions in cyberbullying detection algorithms",
    "Authors": "Singh and Hofenbitzer",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Stack Overflow",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Gender gap, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Austria",
    "DOI": "https://doi.org/10.1007/s10664-019-09685-x",
    "Title": "Gender differences in participation and reward on Stack Overflow",
    "Authors": "May et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "IBM",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3338906.3338937",
    "Title": "Black box fairness testing of machine learning models",
    "Authors": "Aggarwal et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "A large financial institution",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Information quality, User profiling",
    "Method": "Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "Greece",
    "Country of Researchers": "Greece",
    "DOI": "https://doi.org/10.1109/IISA.2019.8900715",
    "Title": "A tool supported framework for the assessment of algorithmic accountability",
    "Authors": "Tagiou et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3299869.3319901",
    "Title": "Interventional fairness: Causal database repair for algorithmic fairness",
    "Authors": "Salimi et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "guru.com, feelancer.com, mturk.com, upwork.com",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Italy",
    "DOI": "https://doi.org/10.1145/3308560.3317587",
    "Title": "Algorithms for fair team formation in online labour marketplaces",
    "Authors": "Barnabo et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Filter bubble, Information quality",
    "Method": "Direct scrape, Sock puppets",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3308558.3312504",
    "Title": "Measuring political personalization of Google news search",
    "Authors": "Le et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Microsoft",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3290605.3300283",
    "Title": "From gender biases to gender-inclusive design: An empirical investigation",
    "Authors": "Vorvoreanu et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Exploitation",
    "Specific Behavior": "User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3290607.3310433",
    "Title": "A mulching proposal: Analysing and improving an algorithmic system for turning the elderly into high-nutrient slurry",
    "Authors": "Keyes et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "YouTube",
    "Behavior": "Distortion",
    "Specific Behavior": "User categorization, User profiling, Group misrepresentation",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "QA",
    "Country of Researchers": "QA",
    "DOI": "https://doi.org/10.1145/3290607.3313034",
    "Title": "Detecting demographic bias in automatically generated personas",
    "Authors": "Salminen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Code",
    "Domain": "Credit/Finance",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1109/ICASSP.2019.8682620",
    "Title": "Bias Mitigation Post-processing for Individual and Group Fairness",
    "Authors": "Lohia et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Facebook",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, Filter bubble, Harmful content, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Brazil, Netherlands, France, India",
    "Country of Researchers": "Brazil, Netherlands, France, India",
    "DOI": "https://doi.org/10.1016/j.peva.2018.09.009",
    "Title": "Fairness in online social network timelines: Measurements, models and mechanism design",
    "Authors": "Hargreaves et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US, Netherlands",
    "DOI": "https://doi.org/10.1145/3287560.3287592",
    "Title": "An empirical study of rich subgroup fairness for machine learning",
    "Authors": "Kearns et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "LinkedIn Corporation",
    "Behavior": "Discrimination",
    "Specific Behavior": "Gender bias, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3287560.3287572",
    "Title": "Bias in BIOS: A case study of semantic representation bias in a high-stakes setting",
    "Authors": "De-Arteaga et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3306618.3314243",
    "Title": "Uncovering and mitigating algorithmic bias through learned latent structure",
    "Authors": "Amini et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085989168&partnerID=40&md5=3a52f15e30281fff453e6e884eade5b7",
    "Title": "Assessing the fairness of graduation predictions",
    "Authors": "Anderson et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1177/1071181319631193",
    "Title": "Gender and Parity in Statistical Prediction of Anterior Carry Hand-Loads from Inertial Sensor Data",
    "Authors": "Lim and D'Souza",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Vision",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Cyprus",
    "DOI": "https://doi.org/10.1007/978-3-030-29390-1_14",
    "Title": "What Is Beautiful Continues to Be Good: People Images and Algorithmic Inferences on Physical Attractiveness",
    "Authors": "Matsangidou and Otterbacher",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072724585&partnerID=40&md5=3f07b7ef67ea74f12b881c12249c62df",
    "Title": "Crank up the volume: Preference bias amplification in collaborative recommendation",
    "Authors": "Lin et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "Facebook",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Denmark, US",
    "DOI": "https://doi.org/10.1177/2053951718819569",
    "Title": "Unsupervised by any other name: Hidden layers of knowledge production in artificial intelligence on social media",
    "Authors": "Bechmann and Bowker",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other)",
    "Method": "Direct scrape, Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "Greece",
    "Country of Researchers": "Greece",
    "DOI": "https://doi.org/10.5441/002/edbt.2019.72",
    "Title": "Identifying bias in name matching tasks",
    "Authors": "Karakasidis and Pitoura",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Personalization, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "Spain, Italy",
    "Country of Researchers": "Spain, Italy",
    "DOI": "https://doi.org/10.1007/978-3-030-15712-8_30",
    "Title": "The effect of algorithmic bias on recommender systems for massive open online courses",
    "Authors": "Boratto et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2019",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Healthcare",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "Canada",
    "DOI": "https://doi.org/10.1109/ACCESS.2019.2900022",
    "Title": "Algorithmic bias in clinical populations - Evaluating and improving facial analysis technology in older adults with dementia",
    "Authors": "Taati et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "DARPA Memex",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3278721.3278782",
    "Title": "Always Lurking: Understanding and Mitigating Bias in Online Human Trafficking Detection",
    "Authors": "Hundman et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "Personalization, Filter bubble, News distribution, User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "IT",
    "Country of Researchers": "Brazil, Netherlands, France, India",
    "DOI": "https://doi.org/10.1109/ASONAM.2018.8508659",
    "Title": "Biases in the facebook news feed: A case study on the Italian elections",
    "Authors": "Hargreaves et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "Amazon",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Hubness, User categorization, Personalization",
    "Method": "Direct scrape",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "AT",
    "Country of Researchers": "Austria",
    "DOI": "https://doi.org/10.1109/ICDMW.2018.00154",
    "Title": "Hubness as a case of technical algorithmic bias in music recommendation",
    "Authors": "Flexer et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "Ranking Facts",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3183713.3193568",
    "Title": "A nutritional label for rankings",
    "Authors": "Yang et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Language Processing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3173574.3173986",
    "Title": "Addressing age-related bias in sentiment analysis",
    "Authors": "Diaz et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Algorithmic bias, Information quality",
    "Method": "Direct scrape, Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "United Kingdom",
    "Country of Researchers": "United Kingdom",
    "DOI": "https://doi.org/10.1002/pra2.2018.14505501061",
    "Title": "The impact of fielding on retrieval performance and bias",
    "Authors": "Wilkie and Azzopardi",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2018",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Hiring",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1007/s10115-017-1116-3",
    "Title": "Auditing black-box models for indirect influence",
    "Authors": "Adler et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution, Personalization, User profiling",
    "Method": "Direct scrape, Code",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK",
    "DOI": "https://doi.org/10.1145/3132847.3133135",
    "Title": "Algorithmic bias: Do good systems make relevant documents more retrievable?",
    "Authors": "Wilkie and Azzopardi",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Mechanical Turk",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3134736",
    "Title": "Simulation experiments on (the absence of) ratings bias in reputation systems",
    "Authors": "Thebault-Spieker et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, News distribution, User profiling, User categorization, Personalization",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "Multiple countries",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/3134677",
    "Title": "Suppressing the Search Engine Manipulation Effect (SEME)",
    "Authors": "Epstein et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other)",
    "Method": "Direct scrape",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "Australia",
    "Country of Researchers": "Australia",
    "DOI": "https://doi.org/10.1109/BigData.2017.8258033",
    "Title": "Discrimination detection by causal effect estimation",
    "Authors": "Li et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "FairTest",
    "Behavior": "Discrimination",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape, Sock puppets, Carrier puppet, Crowdsourcing, Code",
    "Domain": "Other",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, United States",
    "DOI": "https://doi.org/10.1109/EuroSP.2017.29",
    "Title": "FairTest: Discovering Unwarranted Associations in Data-Driven Applications",
    "Authors": "Tramèr et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Bing",
    "Behavior": "Distortion",
    "Specific Behavior": "Gender stereotypes, User categorization, Personalization",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, UK",
    "Country of Researchers": "Cyprus, UK",
    "DOI": "https://doi.org/10.1145/3025453.3025727",
    "Title": "Competent men and warm women: Gender stereotypes and backlash in image search results",
    "Authors": "Otterbacher et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Social Media",
    "Behavior": "Discrimination",
    "Specific Behavior": "Group misrepresentation, User categorization, User profiling, Information quality",
    "Method": "Direct scrape, Crowdsourcing, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Germany, US",
    "DOI": "https://doi.org/10.1145/3025453.3026015",
    "Title": "The effect of population and \"Structural\" biases on social media-based algorithms - A case study in geolocation inference across the urban-rural spectrum",
    "Authors": "Johnson et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Information quality, Filter bubble, User profiling",
    "Method": "Direct scrape, Crowdsourcing",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "CA",
    "Country of Researchers": "CA",
    "DOI": "https://doi.org/10.1145/3020165.3020185",
    "Title": "Making sense of conflicting science information: Exploring bias in the search engine result page",
    "Authors": "Novin and Meyers",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Discrimination (other), User categorization, User profiling",
    "Method": "Direct scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US, UK",
    "Country of Researchers": "UK, US, Sweden",
    "DOI": "https://doi.org/10.1145/3041021.3054197",
    "Title": "Auditing search engines for differential satisfaction across demographics",
    "Authors": "Mehrotra et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Facebook",
    "Behavior": "Distortion",
    "Specific Behavior": "User profiling, Personalization, Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "Denmark",
    "DOI": "https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044516978&partnerID=40&md5=000ed6e1f74e4671ff8c27c210ef5d74",
    "Title": "Keeping it real: From faces and features to social values in deep learning algorithms on social media images",
    "Authors": "Bechmann",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2017",
    "Organization": "Amazon",
    "Behavior": "Discrimination",
    "Specific Behavior": "Harmful content, User categorization, User profiling",
    "Method": "Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "UK, US",
    "Country of Researchers": "UK, US",
    "DOI": "https://doi.org/10.1007/978-3-319-67256-4_32",
    "Title": "Like trainer, like bot? Inheritance of bias in algorithmic content moderation",
    "Authors": "Binns et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2016",
    "Organization": "FindYou",
    "Behavior": "Discrimination",
    "Specific Behavior": "User categorization, User profiling, Discrimination (other), Harmful content",
    "Method": "Direct scrape, Code",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2872518.2890546",
    "Title": "FindYou: A Personal Location Privacy Auditing Tool",
    "Authors": "Riederer et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2015",
    "Organization": "Uber",
    "Behavior": "Exploitation",
    "Specific Behavior": "Price discrimination, Personalization",
    "Method": "Direct scrape, Sock puppets",
    "Domain": "Pricing",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1145/2815675.2815681",
    "Title": "Peeking beneath the hood of uber",
    "Authors": "Chen et al.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, News distribution, Personalization",
    "Method": "Non-persona scrape, Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.1093/joc/jqac009",
    "Title": "Mapping Exposure Diversity: The Divergent Effects of Algorithmic Curation on News Consumption",
    "Authors": "Jürgens, Pascal; Stark, Birgit",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2022",
    "Organization": "Google",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, News distribution, Personalization",
    "Method": "Direct scrape, Non-persona scrape, Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.1080/1369118X.2020.1764605",
    "Title": "Partisan search behavior and Google results in the 2018 U.S. midterm elections",
    "Authors": "Trielli, Daniel; Diakopoulos, Nicholas",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2024",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "News distribution, Filter bubble, Information quality",
    "Method": "Direct scrape, Non-persona scrape, Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.1177/14614448211063899",
    "Title": "No trade-offs between news and entertainment: Evidence from online engagement data",
    "Authors": "Huang, Shengchun; Yang, Tian",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2020",
    "Organization": "Google",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, Personalization, User categorization, User profiling",
    "Method": "Direct scrape, Non-persona scrape, Persona scrape",
    "Domain": "Search",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "US",
    "DOI": "https://doi.org/10.1609/icwsm.v14i1.7352",
    "Title": "The Media Coverage of the 2020 US Presidential Election Candidates through the Lens of Google's Top Stories",
    "Authors": "Kawakami, Anna; Umarova, Khonzodakhon; Mustafaraj, Eni",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Google",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.48550/arXiv.2507.06018",
    "Title": "Campaigning through the lens of Google: A large-scale algorithm audit of Google searches in the run-up to the Swiss Federal Elections 2023",
    "Authors": "",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "Twitter",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Personalization",
    "Method": "Crowdsourcing",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.1038/s41598-023-43980-4",
    "Title": "Crowdsourced audit of Twitter’s recommender systems",
    "Authors": "Bouchaud, Paul; Chavalarias, David; Panahi, Maziyar",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2023",
    "Organization": "",
    "Behavior": "Distortion",
    "Specific Behavior": "Filter bubble, Information quality, News distribution, Personalization, User categorization, User profiling",
    "Method": "Survey",
    "Domain": "Social Media",
    "Language": "English",
    "Country Studied": "US",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.1126/science.abp9364",
    "Title": "How do social media feed algorithms affect attitudes and behavior in an election campaign?",
    "Authors": "Guess, Andrew M.; Malhotra, Neil; Pan, Jennifer; Barberá, Pablo; Allcott, Hunt; Brown, Taylor; Crespo-Tenorio, Adriana; Dimmery, Drew; Freelon, Deen; Gentzkow, Matthew; González-Bailón, Sandra; Kennedy, Edward; Kim, Young Mie; Lazer, David; Moehler, Devra; Nyhan, Brendan; Rivera, Carlos Velasco; Settle, Jaime; Thomas, Daniel Robert; Thorson, Emily; Tromble, Rebekah; Wilkins, Arjun; Wojcieszak, Magdalena; Xiong, Beixian; de Jonge, Chad Kiewiet; Franco, Annie; Mason, Winter; Stroud, Natalie Jomini; Tucker, Joshua A.",
    "Source": "NEEDS HUMAN REVIEW"
  },
  {
    "Year": "2025",
    "Organization": "Twitter",
    "Behavior": "Misjudgement",
    "Specific Behavior": "Personalization, User profiling",
    "Method": "",
    "Domain": "Recommendation",
    "Language": "English",
    "Country Studied": "",
    "Country of Researchers": "",
    "DOI": "https://doi.org/10.48550/arXiv.2509.09826",
    "Title": "The Role of Follow Networks and Twitter's Content Recommender on Partisan Skew and Rumor Exposure during the 2022 U.S. Midterm Election",
    "Authors": "",
    "Source": "NEEDS HUMAN REVIEW"
  }
];
